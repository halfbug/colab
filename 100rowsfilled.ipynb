{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqH/ilL62tdB/mqHUurh74",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/halfbug/colab/blob/main/100rowsfilled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_yLeh0hiW9Iv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_id = '1M8mauGQDZVbXpwQPAlfrKc2suVqtdB5k'\n",
        "sheet_name = \"LevelGuide\"\n",
        "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "df=pd.read_csv(url)\n",
        "# https://docs.google.com/spreadsheets/d/1M8mauGQDZVbXpwQPAlfrKc2suVqtdB5k/edit#gid=816935593"
      ],
      "metadata": {
        "id": "jzAAwhqwYF2I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K85q2qqtYQJC",
        "outputId": "2396c074-d10c-4fca-ac78-d3b626265482"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  join  Hemster ID  \\\n",
            "0       55718 194900722053 30F1GCDS2L 001 Michael Kors       55718   \n",
            "1      55740 196163322728 30S2G9HM6L 1999 Michael Kors       55740   \n",
            "2    55760 196163134963 30S2SCDT3L chambray Michael...       55760   \n",
            "3          55770 193144528056 MM7W775 110 Michael Kors       55770   \n",
            "4    55858 196163135120 30S2SGRL8L CHAMBRAY Michael...       55858   \n",
            "..                                                 ...         ...   \n",
            "134     55653 196108954069 43T2OLFS1D 005 Michael Kors       55653   \n",
            "135     55629 196237053305 MU2814R5PT 100 Michael Kors       55629   \n",
            "136    55625 196163150185 MS2206R50R 3110 Michael Kors       55625   \n",
            "137     55640 196237063922 MU2817O33D 001 Michael Kors       55640   \n",
            "138     55631 723088612322 77Q5928M42 110 Michael Kors       55631   \n",
            "\n",
            "           MK SKU          Description Grade         Garment Type  \\\n",
            "0    194900722053       30F1GCDS2L 001     a                 Bags   \n",
            "1    196163322728      30S2G9HM6L 1999     a                 Bags   \n",
            "2    196163134963  30S2SCDT3L chambray     a                 Bags   \n",
            "3    193144528056          MM7W775 110     a              Scarves   \n",
            "4    196163135120  30S2SGRL8L CHAMBRAY     a                 Bags   \n",
            "..            ...                  ...   ...                  ...   \n",
            "134  196108954069       43T2OLFS1D 005     a                Shoes   \n",
            "135  196237053305       MU2814R5PT 100     a       Sleeveless Top   \n",
            "136  196163150185      MS2206R50R 3110     a            Outerwear   \n",
            "137  196237063922       MU2817O33D 001     a  Basic Sleeved Dress   \n",
            "138  723088612322       77Q5928M42 110     a            Outerwear   \n",
            "\n",
            "    Category Type     MSRP  brand   image  Sold on amazon  color  \\\n",
            "0       Accessory  $200.00     NaN    NaN             NaN    NaN   \n",
            "1       Accessory  $138.00     NaN    NaN             NaN    NaN   \n",
            "2       Accessory  $150.00     NaN    NaN             NaN    NaN   \n",
            "3       Accessory  $100.00     NaN    NaN             NaN    NaN   \n",
            "4       Accessory  $250.00     NaN    NaN             NaN    NaN   \n",
            "..            ...      ...     ...    ...             ...    ...   \n",
            "134      Footwear  $110.00     NaN    NaN             NaN    NaN   \n",
            "135       Apparel  $150.00     NaN    NaN             NaN    NaN   \n",
            "136       Apparel  $595.00     NaN    NaN             NaN    NaN   \n",
            "137       Apparel  $260.00     NaN    NaN             NaN    NaN   \n",
            "138       Apparel  $220.00     NaN    NaN             NaN    NaN   \n",
            "\n",
            "     Amazon price  ASIN  UPC  \n",
            "0             NaN   NaN  NaN  \n",
            "1             NaN   NaN  NaN  \n",
            "2             NaN   NaN  NaN  \n",
            "3             NaN   NaN  NaN  \n",
            "4             NaN   NaN  NaN  \n",
            "..            ...   ...  ...  \n",
            "134           NaN   NaN  NaN  \n",
            "135           NaN   NaN  NaN  \n",
            "136           NaN   NaN  NaN  \n",
            "137           NaN   NaN  NaN  \n",
            "138           NaN   NaN  NaN  \n",
            "\n",
            "[139 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logger"
      ],
      "metadata": {
        "id": "4TygYEzH7paq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "class Logger:\n",
        "    def __init__(self, logger_name):\n",
        "        self.logger = logging.getLogger(logger_name)\n",
        "        self.logger.setLevel(logging.DEBUG)\n",
        "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "        ch = logging.StreamHandler()\n",
        "        ch.setFormatter(formatter)\n",
        "        self.logger.addHandler(ch)"
      ],
      "metadata": {
        "id": "HxMn1BfNVt4K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ExcelProcessor**"
      ],
      "metadata": {
        "id": "rgKOubuG7mj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExcelProcessor:\n",
        "    def __init__(self, file_path=None, sheet_id=None, sheet_name=\"Excel file\"):\n",
        "        # Example usage for opening a Google Sheet:\n",
        "        # sheet_id = '1M8mauGQDZVbXpwQPAlfrKc2suVqtdB5k'\n",
        "        # sheet_name = \"LevelGuide\"\n",
        "        # processor = ExcelProcessor(sheet_id=sheet_id, sheet_name=sheet_name)\n",
        "\n",
        "        if file_path:\n",
        "            self.df = pd.read_excel(file_path)\n",
        "        elif sheet_id and sheet_name:\n",
        "            url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "            self.df = pd.read_csv(url)\n",
        "        else:\n",
        "            raise ValueError(\"Either provide a file path or Google Sheet ID and sheet name.\")\n",
        "        self.logger = Logger(__name__).logger\n",
        "\n",
        "    def get_empty_columns_names(self):\n",
        "        empty_columns = self.df.columns[self.df.isnull().any()].tolist()\n",
        "        return empty_columns\n",
        "\n",
        "    def get_filled_columns_names(self):\n",
        "        filled_columns = self.df.columns[self.df.notnull().any()].tolist()\n",
        "        return filled_columns\n",
        "\n",
        "    def list_columns_with_values(self,num_columns=None):\n",
        "        non_empty_columns = self.df.columns[self.df.notnull().any()].tolist()\n",
        "        filtered_df = self.df[non_empty_columns]\n",
        "        if num_columns:\n",
        "            return filtered_df.values[:, :num_columns].tolist()\n",
        "        else:\n",
        "            return filtered_df.values.tolist()\n",
        "        return columns_with_values\n",
        "\n",
        "    def get_all_rows(self):\n",
        "        return self.df.values.tolist()\n",
        "\n",
        "    def get_all_rows_values(self):\n",
        "        non_empty_columns = self.df.columns[self.df.notnull().any()].tolist()\n",
        "        filtered_df = self.df[non_empty_columns]\n",
        "        return filtered_df.values.tolist()\n",
        "\n",
        "    def get_total_rows_columns(self):\n",
        "        total_rows, total_columns = self.df.shape\n",
        "        self.logger.info(\"get total rows and columns in the sheet\")\n",
        "        return total_rows, total_columns\n",
        "        # Example usage to get total rows and columns in the sheet\n",
        "        # total_rows, total_columns = processor.get_total_rows_columns()\n",
        "        # print(\"Total rows:\", total_rows)\n",
        "        # print(\"Total columns:\", total_columns)"
      ],
      "metadata": {
        "id": "bJCLz2UAjiqN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_id = '1M8mauGQDZVbXpwQPAlfrKc2suVqtdB5k'\n",
        "sheet_name = \"LevelGuide\"\n",
        "processor = ExcelProcessor(sheet_id=sheet_id, sheet_name=sheet_name)\n",
        "\n",
        "print(\"Empty columns:\", processor.get_empty_columns_names())\n",
        "\n",
        "# print(\"Columns with values:\", processor.get_filled_columns_names()[ :3])\n",
        "print(\"Columns with values:\", ' '.join(processor.get_filled_columns_names()))\n",
        "\n",
        "print(\"All rows of the sheet:\")\n",
        "all_rows = processor.get_all_rows_values()\n",
        "for row in all_rows:\n",
        "    # print(row)\n",
        "    row_str = \", \".join(map(str, row))\n",
        "    # print(row_str)\n",
        "\n",
        "# Example usage to get total rows and columns in the sheet\n",
        "total_rows, total_columns = processor.get_total_rows_columns()\n",
        "print(\"Total rows:\", total_rows)\n",
        "print(\"Total columns:\", total_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR9oYhMdlTJn",
        "outputId": "28d96f58-8570-4b03-9cd0-7e5c5f7a1b8c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-03-25 10:11:00,102 - __main__ - INFO - get total rows and columns in the sheet\n",
            "INFO:__main__:get total rows and columns in the sheet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty columns: ['brand ', 'image', 'Sold on amazon', 'color', 'Amazon price', 'ASIN', 'UPC']\n",
            "Columns with values: join Hemster ID MK SKU Description Grade Garment Type Category Type MSRP\n",
            "All rows of the sheet:\n",
            "Total rows: 139\n",
            "Total columns: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for columns with empty values\n",
        "empty_columns = df.columns[df.isnull().any()].tolist()\n",
        "empty_columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjYTK9FpbL9s",
        "outputId": "01564bc8-ce07-4c03-dfd6-093905ea79a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['brand ', 'image', 'Sold on amazon', 'color', 'Amazon price', 'ASIN', 'UPC']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HelperText"
      ],
      "metadata": {
        "id": "SQ7dIU4G7dDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HelperText:\n",
        "    @staticmethod\n",
        "    def format_string(input_string):\n",
        "        formatted_string = \"\"\n",
        "\n",
        "        # Split the input string into separate lines\n",
        "        lines = input_string.split('\\n')\n",
        "\n",
        "        # Iterate through each line\n",
        "        for line in lines:\n",
        "            # Check if the line contains a colon ':'\n",
        "            if ':' in line:\n",
        "                # Split the line into key and value based on the colon ':'\n",
        "                key, value = line.split(':', 1)\n",
        "                # Format the key and value and add them to the formatted string\n",
        "                formatted_string += f\"{key.strip()}: {value.strip()} \"\n",
        "            else:\n",
        "                # If the line does not contain a colon, add it as is to the formatted string\n",
        "                formatted_string += f\"{line.strip()} \"\n",
        "\n",
        "        return formatted_string\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def clear_code(input_string):\n",
        "        string_encode = input_string.encode(\"ascii\", \"ignore\")\n",
        "        input_string = string_encode.decode()\n",
        "        return(input_string)\n",
        "\n",
        "# Example usage:\n",
        "helper = HelperText()\n",
        "\n",
        "# Format a string\n",
        "formatted_string = helper.format_string(\"Your input string\")\n",
        "print(\"Formatted string:\", formatted_string)\n",
        "\n",
        "# Clear code from a string\n",
        "cleaned_string = helper.clear_code(\"Your input string with code\")\n",
        "print(\"Cleaned string:\", cleaned_string)\n"
      ],
      "metadata": {
        "id": "JVrf2YGm3aQp",
        "outputId": "b5599f1e-7b33-4c5e-a9d5-03b09b9678d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatted string: Your input string \n",
            "Cleaned string: Your input string with code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **WebScraper**"
      ],
      "metadata": {
        "id": "ZG2x1i3j7TL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import userdata\n",
        "\n",
        "class WebScraper:\n",
        "    def __init__(self):\n",
        "        self.base_url = \"https://www.google.com/search?q=\"\n",
        "        self.api_key = userdata.get('GOOGLE_SEARCH_API')\n",
        "        self.service = build(\"customsearch\", \"v1\", developerKey=self.api_key)\n",
        "        self.logger = Logger(__name__).logger\n",
        "\n",
        "    def google_scraper(self, query):\n",
        "        try:\n",
        "          response = requests.get(self.base_url+query.lower().replace(' ', '+'))\n",
        "          soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "          # find first five link's content\n",
        "          # anchor_tags = soup.find_all('a', href=True)\n",
        "          # hrefs = []\n",
        "          # content = \"\"\n",
        "          # for tag in anchor_tags:\n",
        "          #   href = tag.get('href')\n",
        "          #   if href and href.startswith(\"/url?q=https\") and \"google\" not in href.lower():  # Check if href exists (it might be None)\n",
        "          #     parts = href.split('&', 1)\n",
        "          #     parts = parts[0].split('/url?q=',1)\n",
        "          #     # print(parts)\n",
        "          #     hrefs.append(parts[1])\n",
        "          #     scraped_content = scrape_text(parts[1])\n",
        "          #     content += scraped_content + \"\\n ***\"\n",
        "              # print(scraped_content)\n",
        "          # print(hrefs[:5])\n",
        "\n",
        "\n",
        "\n",
        "          body_content = soup.find('body')  # Find the body tag\n",
        "\n",
        "          if body_content:\n",
        "            # Extract only the text content from the body tag\n",
        "              text_content = body_content.get_text(strip=True)\n",
        "              # print(\"\\033[34m\" + text_content )\n",
        "\n",
        "\n",
        "\n",
        "              return helper.clear_code(text_content)    #format_string(content)\n",
        "        except Exception as e:\n",
        "          print(f\"Error occurred while scraping: {e}\")\n",
        "          return \"No search result found: Unknown\"\n",
        "        self.logger.info(\"Scraping Google search results for: %s\", query)\n",
        "\n",
        "    def scrape_text(self,url):\n",
        "    # Function to scrape the webpage for availability information\n",
        "      try:\n",
        "          response = requests.get(url)\n",
        "          soup = BeautifulSoup(response.content, 'html.parser')\n",
        "          # Search for specific keywords like \"stock availability\" on the webpage\n",
        "\n",
        "          # Step 3: Extract metadata\n",
        "          meta_tags = soup.find_all('meta')\n",
        "          metadata = {}\n",
        "          for tag in meta_tags:\n",
        "              if 'name' in tag.attrs:\n",
        "                  name = tag.attrs['name']\n",
        "                  content = tag.attrs.get('content', '')\n",
        "                  metadata[name] = content\n",
        "              elif 'property' in tag.attrs:  # For OpenGraph metadata\n",
        "                  property = tag.attrs['property']\n",
        "                  content = tag.attrs.get('content', '')\n",
        "                  metadata[property] = content\n",
        "\n",
        "          # Display the metadata\n",
        "          # for key, value in metadata.items():\n",
        "          #     print(f\"{key}: {value}\")\n",
        "\n",
        "          # print( metadata)\n",
        "\n",
        "          meta_tag = self.extract_product_info([metadata])\n",
        "\n",
        "              # Find all link elements with the 'as' attribute set to 'image'\n",
        "          image_links = soup.find_all('link', {'rel': 'preload', 'as': 'image'})\n",
        "\n",
        "          # Extract and print the href attributes\n",
        "          images = ''\n",
        "          for link in image_links:\n",
        "              image_url = link.get('href')\n",
        "              if image_url:\n",
        "                  if image_url.startswith(\"//\"):\n",
        "                    # Add protocol (http assumed):\n",
        "                    image_url= f\"http:{image_url}\"\n",
        "                  images = images +\",\"+ image_url\n",
        "                  # print(image_url)\n",
        "\n",
        "          body_content = soup.find('body')  # Find the body tag\n",
        "          print(body_content)\n",
        "          if body_content:\n",
        "            # Extract only the text content from the body tag\n",
        "              text_content = body_content.get_text(strip=True)\n",
        "\n",
        "              # Search for either \"stock\" or \"stock availability\" in the text content\n",
        "              # print(text_content)\n",
        "              string_encode = text_content.encode(\"ascii\", \"ignore\")\n",
        "              text_content = string_encode.decode()\n",
        "              return text_content + meta_tag + \"Images : \" + images\n",
        "          return f\"Content: Unknown on {url}\"\n",
        "      except Exception as e:\n",
        "          print(f\"Error occurred while scraping: {e}\")\n",
        "          return f\"Content: Unknown on {url}\"\n",
        "\n",
        "    def extract_product_info(self, meta_tags):\n",
        "        # Function to extract product information from meta tags\n",
        "        product_info = \"\"\n",
        "        for meta_tag in meta_tags:\n",
        "            if 'og:title' in meta_tag:\n",
        "                product_info += f\"\\n ***Title: {meta_tag['og:title']}\\n\"\n",
        "            if 'og:description' in meta_tag:\n",
        "                product_info += f\"Description: {meta_tag['og:description']}\\n\"\n",
        "            if 'og:price:amount' in meta_tag and 'og:price:currency' in meta_tag:\n",
        "                product_info += f\"Price: {meta_tag['og:price:amount']} {meta_tag['og:price:currency']}\\n\"\n",
        "            if 'og:image' in meta_tag:\n",
        "                    if len(meta_tag['og:image']) <= 200:  # Check if URL length is less than or equal to 200\n",
        "                        product_info += f\"Image URL: {meta_tag['og:image']} \\n\"\n",
        "            if 'og:url' in meta_tag:\n",
        "                product_info += f\"URL: {meta_tag['og:url']} \\n\"\n",
        "                # Call function to extract availability information\n",
        "                availability_info = self.extract_availability(meta_tag['og:url'])\n",
        "                product_info += f\"{availability_info}\\n\"\n",
        "                # Extract ASIN from URL if it's an Amazon link\n",
        "                asin_match = re.search(r'/dp/(\\w+)', meta_tag['og:url'])\n",
        "                if asin_match:\n",
        "                    product_info += f\"ASIN: {asin_match.group(1)} \\n\"\n",
        "            if 'og:site_name' in meta_tag:\n",
        "                product_info += f\"Site Name: {meta_tag['og:site_name']} \\n\"\n",
        "            if 'og:availability' in meta_tag:\n",
        "                product_info += f\"Availability: {meta_tag['og:availability']} \\n\"\n",
        "            if 'og:type' in meta_tag:\n",
        "                    product_info += f\"type: {meta_tag['og:type']} \\n\"\n",
        "            else:\n",
        "              product_info += f\"type: text \\n\"\n",
        "        return product_info\n",
        "\n",
        "\n",
        "    def extract_availability(self,url):\n",
        "    # Function to scrape the webpage for availability information\n",
        "      try:\n",
        "          response = requests.get(url)\n",
        "          soup = BeautifulSoup(response.content, 'html.parser')\n",
        "          # Search for specific keywords like \"stock availability\" on the webpage\n",
        "\n",
        "          body_content = soup.find('body')  # Find the body tag\n",
        "\n",
        "          if body_content:\n",
        "            # Extract only the text content from the body tag\n",
        "              text_content = body_content.get_text(strip=True)\n",
        "              # Search for either \"stock\" or \"stock availability\" in the text content\n",
        "              # print(text_content)\n",
        "              #  availability_pattern = re.compile(r\"(?:stock|stock|availability|Number\\sof\\sItems\\s*(\\d+)|in\\s*stock|(\\w+)\\s*stock\\s*(\\w+))\", re.IGNORECASE)\n",
        "\n",
        "              availability_pattern = re.compile(r\"(?:stock|stock|availability|in\\s*stock)\", re.IGNORECASE)\n",
        "              match = re.search(availability_pattern, text_content)\n",
        "              # print(match.groups())\n",
        "              if match:\n",
        "                  # print(match.group(0))\n",
        "                  return f\"Availability: {match.group(0).strip()}\"\n",
        "          # If specific keywords not found, return \"Scraped Availability: Unknown\"\n",
        "          return \"Availability: Unknown\"\n",
        "      except Exception as e:\n",
        "          print(f\"Error occurred while scraping: {e}\")\n",
        "          return \"Availability: Unknown\"\n",
        "\n",
        "    def search_google(self,query,num_results):\n",
        "      \"\"\"\n",
        "      Performs a custom search  using the Google Custom Search API.\n",
        "\n",
        "      Args:\n",
        "          query (str): The search query to use.\n",
        "          num_results (int, optional): The number of image search results to return (default: 3).\n",
        "\n",
        "      Returns:\n",
        "          str: A string containing information about the image search results. Each result includes the image URL and its corresponding link.\n",
        "      \"\"\"\n",
        "      # user_query= extract_text_between_hashes(query)\n",
        "      results = self.service.cse().list(\n",
        "          q=query, cx=userdata.get('GOOGLE_CSE_ID'),  # Replace with your custom search engine ID\n",
        "          # searchType=\"image\",  # Specify image search\n",
        "          num=3\n",
        "      ).execute()\n",
        "\n",
        "      search_results = \" \"\n",
        "      for item in results.get(\"items\", []):\n",
        "          # for key, value in item.items():\n",
        "          #   print(\"\\033[32m\" + f\"{key}: {value}\" + \"\\033[0m\")\n",
        "          image_url = item[\"pagemap\"][\"cse_image\"][0][\"src\"]\n",
        "          # print(item[\"pagemap\"][\"metatags\"])\n",
        "          # search_results.append({\"link\":item[\"link\"] ,\n",
        "          #                       \"title\": item[\"title\"] ,\n",
        "          #                       \"snippets\":item[\"snippet\"],\n",
        "          #                       \"image\": image_url,\n",
        "          #                       \"meta\": extract_product_info(item[\"pagemap\"][\"metatags\"])})\n",
        "          search_results += self.extract_product_info(item[\"pagemap\"][\"metatags\"])\n",
        "          search_results += f\"image2: {image_url} \\n\"\n",
        "          search_results += f\"link: {item['link']}\"\n",
        "\n",
        "      # len(search_results)\n",
        "      return helper.clear_code(search_results)\n",
        "\n",
        "\n",
        "    def combined_scraped_api_search(self, query):\n",
        "        # Function to perform a combined search using both scraping and API\n",
        "        scraped_results = self.google_scraper(query)\n",
        "        search_api_results = self.search_google(query,3)\n",
        "        return f\"\"\"{scraped_results} \\n {search_api_results} \"\"\"\n",
        "        self.logger.info(\"Performing combined search for: %s\", query)\n",
        "\n",
        "# Example usage:\n",
        "scraper = WebScraper()\n",
        "query = \"Apotheke 3 wick candles collection price images\"\n",
        "\n",
        "scraper.google_scraper(query)\n",
        "scraper.combined_scraped_api_search(query)"
      ],
      "metadata": {
        "id": "EM4eSJq0m6CT",
        "outputId": "22d6a3cf-1f9c-46a1-abe0-c91d5179e992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'InloggenInloggenVoordat je verdergaat naar GoogleWe gebruikencookiesen gegevens voor het volgende:Google-services leveren en onderhoudenUitval bijhouden en bescherming bieden tegen spam, fraude en misbruikDoelgroepbetrokkenheid en sitestatistieken meten om inzicht te krijgen in hoe onze services worden gebruikt en de kwaliteit van die services te verbeterenAls je Alles accepteren kiest, gebruiken we cookies en gegevens ook voor het volgende:Nieuwe services ontwikkelen en verbeterenAdvertenties laten zien en de effectiviteit ervan metenGepersonaliseerde content laten zien (afhankelijk van je instellingen)Gepersonaliseerde advertenties laten zien (afhankelijk van je instellingen)Als je Alles afwijzen kiest, gebruiken we cookies niet voor deze aanvullende doeleinden.Niet-gepersonaliseerde content wordt benvloed door factoren zoals de content die je op dat moment bekijkt, activiteit in je actieve zoeksessie en je locatie. Niet-gepersonaliseerde advertenties worden benvloed door de content die je op dat moment bekijkt en je algemene locatie. Gepersonaliseerde content en advertenties kunnen ook relevantere resultaten, aanbevelingen en op jou toegespitste advertenties omvatten die zijn gebaseerd op eerdere activiteit van deze browser, zoals uitgevoerde Google-zoekopdrachten. We gebruiken cookies en gegevens ook om te zorgen dat de functionaliteit geschikt is voor je leeftijd, als dit relevant is.Selecteer Meer opties om meer informatie te bekijken, waaronder informatie over hoe je je privacyinstellingen beheert. Je kunt ook altijd naar g.co/privacytools gaan.Meer optiesAfrikaansazrbaycanbosanskicataletinaCymraegDanskDeutscheestiEnglish(United Kingdom)English(United States)Espaol(Espaa)Espaol(Latinoamrica)euskaraFilipinoFranais(Canada)Franais(France)GaeilgegalegoHrvatskiIndonesiaisiZuluslenskaItalianoKiswahililatvieulietuvimagyarMelayuNederlandsnorskozbekpolskiPortugus(Brasil)Portugus(Portugal)romnshqipSloveninasloveninasrpski (latinica)SuomiSvenskaTing VitTrke ()PrivacybeleidServicevoorwaarden \\n  \\n ***Title: Apotheke 3-Wick Candles Collection\\nDescription: Captivating Fragrance: Transform any living space with the unforgettable scent of Charcoal 3-Wick Candle from APOTHEKE. Our candles are hand poured and made with a proprietary blend of essential and perfume-grade oils for a long-lasting fragrance. Each 26 oz candle burns for approximately 120 - 1...\\nURL: https://www.amazon.com/dp/B07PMY9PK6/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B07PMY9PK6 \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/61yZbIMhvVL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/Scented-Candles-Home-Soy-Wax-Jar-Candle/dp/B07PMY9PK6\\n ***Title: MSRP/MAP Policy\\nDescription: In order to preserve its reputation for providing customers with high value products and strong after-sales support, and to further enhance the APOTHEKE brand image and its competitiveness in the marketplace, APOTHEKE is unilaterally instituting a policy of minimum advertised price standards for APOTHEKE products.\\nImage URL: http:files/Charcoal2.jpg \\nURL: https://apothekeco.com/pages/msrpmap-policy \\nAvailability: Unknown\\nSite Name: APOTHEKE \\ntype: website \\nimage2: https://hello.zonos.com/images/flags/US.png \\nlink: https://apothekeco.com/pages/msrpmap-policy\\n ***Title: APOTHEKE Market Collection Luxury Scented 3-Wick Jar Candle, Purple Basil, 32 oz - Basil, Ginger Lime & Lily of The Valley Scent, Strong Fragrance, Aromatherapy, Long Lasting, Hand Poured in USA, Soy\\nDescription: APOTHEKE Luxury Jar Candles Purple Basil - 32 Ounce 3-Wick Jar Candle SCENT PROFILE: Purple basil, spicy ginger and juicy lime zest mingle with hints of lily of the valley Our candles are hand-poured with perfume-grade fragrance oils and a high quality soy wax blend. Each scent is formulated with...\\nURL: https://www.amazon.com/dp/B09RTPD6ZN/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B09RTPD6ZN \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/618bD-pCyRL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/APOTHEKE-Market-Collection-Luxury-Scented/dp/B09RTPD6ZN '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scraper.google_scraper(\"Apotheke 3 wick candles collection\")"
      ],
      "metadata": {
        "id": "qt2HTqzKykFj",
        "outputId": "2f620299-35d4-4621-c18a-9e0f07d9fd6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'InloggenInloggenVoordat je verdergaat naar GoogleWe gebruikencookiesen gegevens voor het volgende:Google-services leveren en onderhoudenUitval bijhouden en bescherming bieden tegen spam, fraude en misbruikDoelgroepbetrokkenheid en sitestatistieken meten om inzicht te krijgen in hoe onze services worden gebruikt en de kwaliteit van die services te verbeterenAls je Alles accepteren kiest, gebruiken we cookies en gegevens ook voor het volgende:Nieuwe services ontwikkelen en verbeterenAdvertenties laten zien en de effectiviteit ervan metenGepersonaliseerde content laten zien (afhankelijk van je instellingen)Gepersonaliseerde advertenties laten zien (afhankelijk van je instellingen)Als je Alles afwijzen kiest, gebruiken we cookies niet voor deze aanvullende doeleinden.Niet-gepersonaliseerde content wordt benvloed door factoren zoals de content die je op dat moment bekijkt, activiteit in je actieve zoeksessie en je locatie. Niet-gepersonaliseerde advertenties worden benvloed door de content die je op dat moment bekijkt en je algemene locatie. Gepersonaliseerde content en advertenties kunnen ook relevantere resultaten, aanbevelingen en op jou toegespitste advertenties omvatten die zijn gebaseerd op eerdere activiteit van deze browser, zoals uitgevoerde Google-zoekopdrachten. We gebruiken cookies en gegevens ook om te zorgen dat de functionaliteit geschikt is voor je leeftijd, als dit relevant is.Selecteer Meer opties om meer informatie te bekijken, waaronder informatie over hoe je je privacyinstellingen beheert. Je kunt ook altijd naar g.co/privacytools gaan.Meer optiesAfrikaansazrbaycanbosanskicataletinaCymraegDanskDeutscheestiEnglish(United Kingdom)English(United States)Espaol(Espaa)Espaol(Latinoamrica)euskaraFilipinoFranais(Canada)Franais(France)GaeilgegalegoHrvatskiIndonesiaisiZuluslenskaItalianoKiswahililatvieulietuvimagyarMelayuNederlandsnorskozbekpolskiPortugus(Brasil)Portugus(Portugal)romnshqipSloveninasloveninasrpski (latinica)SuomiSvenskaTing VitTrke ()PrivacybeleidServicevoorwaarden'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scraper.search_google(\"Apotheke 3 wick candles collection price images\",3)"
      ],
      "metadata": {
        "id": "SypGSDOh78Q4",
        "outputId": "21038ed5-1a99-4139-e1ed-aaeb04edf0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\n ***Title: Apotheke 3-Wick Candles Collection\\nDescription: Captivating Fragrance: Transform any living space with the unforgettable scent of Charcoal 3-Wick Candle from APOTHEKE. Our candles are hand poured and made with a proprietary blend of essential and perfume-grade oils for a long-lasting fragrance. Each 26 oz candle burns for approximately 120 - 1...\\nURL: https://www.amazon.com/dp/B07PMY9PK6/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B07PMY9PK6 \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/61yZbIMhvVL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/Scented-Candles-Home-Soy-Wax-Jar-Candle/dp/B07PMY9PK6\\n ***Title: MSRP/MAP Policy\\nDescription: In order to preserve its reputation for providing customers with high value products and strong after-sales support, and to further enhance the APOTHEKE brand image and its competitiveness in the marketplace, APOTHEKE is unilaterally instituting a policy of minimum advertised price standards for APOTHEKE products.\\nImage URL: http:files/Charcoal2.jpg \\nURL: https://apothekeco.com/pages/msrpmap-policy \\nAvailability: Unknown\\nSite Name: APOTHEKE \\ntype: website \\nimage2: https://hello.zonos.com/images/flags/US.png \\nlink: https://apothekeco.com/pages/msrpmap-policy\\n ***Title: APOTHEKE Market Collection Luxury Scented 3-Wick Jar Candle, Purple Basil, 32 oz - Basil, Ginger Lime & Lily of The Valley Scent, Strong Fragrance, Aromatherapy, Long Lasting, Hand Poured in USA, Soy\\nDescription: APOTHEKE Luxury Jar Candles Purple Basil - 32 Ounce 3-Wick Jar Candle SCENT PROFILE: Purple basil, spicy ginger and juicy lime zest mingle with hints of lily of the valley Our candles are hand-poured with perfume-grade fragrance oils and a high quality soy wax blend. Each scent is formulated with...\\nURL: https://www.amazon.com/dp/B09RTPD6ZN/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B09RTPD6ZN \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/618bD-pCyRL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/APOTHEKE-Market-Collection-Luxury-Scented/dp/B09RTPD6ZN'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document splitting"
      ],
      "metadata": {
        "id": "h9zT7ShXgoNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import openai\n",
        "  from langchain_openai import ChatOpenAI\n",
        "except:\n",
        "    !pip install openai\n",
        "    !pip install langchain\n",
        "    !pip install langchain-openai"
      ],
      "metadata": {
        "id": "xPDvuNzT5vac",
        "outputId": "f38e5858-39c1-4c7f-e5f9-3a1387530add",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.14.2-py3-none-any.whl (262 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/262.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m204.8/262.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.14.2\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
            "  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (3.7.1)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langsmith-0.1.31 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.1-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.1.33)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.14.2)\n",
            "Collecting tiktoken<1,>=0.5.2 (from langchain-openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (0.1.31)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (8.2.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.10.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain-openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.0.7)\n",
            "Installing collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.1.1 tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "class DocumentSplitter:\n",
        "    def __init__(self, chunk_size=700, chunk_overlap=150):\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "        self.splits = []\n",
        "\n",
        "    def split_document(self, document):\n",
        "        self.splits = self.text_splitter.split_text(document)\n",
        "        return self.splits"
      ],
      "metadata": {
        "id": "Fin9bKHRgvZ8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = DocumentSplitter()\n",
        "# Split the document\n",
        "splits = splitter.split_document(scraper.combined_scraped_api_search(query))"
      ],
      "metadata": {
        "id": "oply5pAlhoLj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPv3eOfAiy2F",
        "outputId": "ddadeb50-9c89-4559-b302-6ec87afc41c4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['InloggenInloggenVoordat je verdergaat naar GoogleWe gebruikencookiesen gegevens voor het volgende:Google-services leveren en onderhoudenUitval bijhouden en bescherming bieden tegen spam, fraude en misbruikDoelgroepbetrokkenheid en sitestatistieken meten om inzicht te krijgen in hoe onze services worden gebruikt en de kwaliteit van die services te verbeterenAls je Alles accepteren kiest, gebruiken we cookies en gegevens ook voor het volgende:Nieuwe services ontwikkelen en verbeterenAdvertenties laten zien en de effectiviteit ervan metenGepersonaliseerde content laten zien (afhankelijk van je instellingen)Gepersonaliseerde advertenties laten zien (afhankelijk van je instellingen)Als je Alles',\n",
              " 'content laten zien (afhankelijk van je instellingen)Gepersonaliseerde advertenties laten zien (afhankelijk van je instellingen)Als je Alles afwijzen kiest, gebruiken we cookies niet voor deze aanvullende doeleinden.Niet-gepersonaliseerde content wordt benvloed door factoren zoals de content die je op dat moment bekijkt, activiteit in je actieve zoeksessie en je locatie. Niet-gepersonaliseerde advertenties worden benvloed door de content die je op dat moment bekijkt en je algemene locatie. Gepersonaliseerde content en advertenties kunnen ook relevantere resultaten, aanbevelingen en op jou toegespitste advertenties omvatten die zijn gebaseerd op eerdere activiteit van deze browser, zoals',\n",
              " 'relevantere resultaten, aanbevelingen en op jou toegespitste advertenties omvatten die zijn gebaseerd op eerdere activiteit van deze browser, zoals uitgevoerde Google-zoekopdrachten. We gebruiken cookies en gegevens ook om te zorgen dat de functionaliteit geschikt is voor je leeftijd, als dit relevant is.Selecteer Meer opties om meer informatie te bekijken, waaronder informatie over hoe je je privacyinstellingen beheert. Je kunt ook altijd naar g.co/privacytools gaan.Meer optiesAfrikaansazrbaycanbosanskicataletinaCymraegDanskDeutscheestiEnglish(United Kingdom)English(United',\n",
              " 'ook altijd naar g.co/privacytools gaan.Meer optiesAfrikaansazrbaycanbosanskicataletinaCymraegDanskDeutscheestiEnglish(United Kingdom)English(United States)Espaol(Espaa)Espaol(Latinoamrica)euskaraFilipinoFranais(Canada)Franais(France)GaeilgegalegoHrvatskiIndonesiaisiZuluslenskaItalianoKiswahililatvieulietuvimagyarMelayuNederlandsnorskozbekpolskiPortugus(Brasil)Portugus(Portugal)romnshqipSloveninasloveninasrpski (latinica)SuomiSvenskaTing VitTrke ()PrivacybeleidServicevoorwaarden',\n",
              " '***Title: Apotheke 3-Wick Candles Collection\\nDescription: Captivating Fragrance: Transform any living space with the unforgettable scent of Charcoal 3-Wick Candle from APOTHEKE. Our candles are hand poured and made with a proprietary blend of essential and perfume-grade oils for a long-lasting fragrance. Each 26 oz candle burns for approximately 120 - 1...\\nURL: https://www.amazon.com/dp/B07PMY9PK6/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B07PMY9PK6 \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/61yZbIMhvVL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/Scented-Candles-Home-Soy-Wax-Jar-Candle/dp/B07PMY9PK6\\n ***Title: MSRP/MAP Policy',\n",
              " 'link: https://www.amazon.com/Scented-Candles-Home-Soy-Wax-Jar-Candle/dp/B07PMY9PK6\\n ***Title: MSRP/MAP Policy\\nDescription: In order to preserve its reputation for providing customers with high value products and strong after-sales support, and to further enhance the APOTHEKE brand image and its competitiveness in the marketplace, APOTHEKE is unilaterally instituting a policy of minimum advertised price standards for APOTHEKE products.\\nImage URL: http:files/Charcoal2.jpg \\nURL: https://apothekeco.com/pages/msrpmap-policy \\nAvailability: Unknown\\nSite Name: APOTHEKE \\ntype: website \\nimage2: https://hello.zonos.com/images/flags/US.png \\nlink: https://apothekeco.com/pages/msrpmap-policy',\n",
              " 'Site Name: APOTHEKE \\ntype: website \\nimage2: https://hello.zonos.com/images/flags/US.png \\nlink: https://apothekeco.com/pages/msrpmap-policy\\n ***Title: APOTHEKE Market Collection Luxury Scented 3-Wick Jar Candle, Purple Basil, 32 oz - Basil, Ginger Lime & Lily of The Valley Scent, Strong Fragrance, Aromatherapy, Long Lasting, Hand Poured in USA, Soy\\nDescription: APOTHEKE Luxury Jar Candles Purple Basil - 32 Ounce 3-Wick Jar Candle SCENT PROFILE: Purple basil, spicy ginger and juicy lime zest mingle with hints of lily of the valley Our candles are hand-poured with perfume-grade fragrance oils and a high quality soy wax blend. Each scent is formulated with...',\n",
              " 'URL: https://www.amazon.com/dp/B09RTPD6ZN/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B09RTPD6ZN \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/618bD-pCyRL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/APOTHEKE-Market-Collection-Luxury-Scented/dp/B09RTPD6ZN']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings"
      ],
      "metadata": {
        "id": "0iS6Hy_FFP3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "ATpG3jg6ILVU",
        "outputId": "59375c72-6650-40ac-d52c-6b47eff5cc0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.4.24)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.1.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.4)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.110.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.29.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.10.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.17.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.3.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.2)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (29.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.9.15)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.36.3)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.7)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "class EmbeddingProcessor:\n",
        "    def __init__(self, persist_directory='docs/chroma/'):\n",
        "        os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "        openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
        "        self.embedding = OpenAIEmbeddings()\n",
        "        self.persist_directory = persist_directory\n",
        "\n",
        "        self.vectordb = None\n",
        "\n",
        "    def setup_vector_store(self):\n",
        "        import sys\n",
        "        sys.path.append('../..')\n",
        "\n",
        "        # Remove old database files if any\n",
        "        self.clear_vector_store()\n",
        "\n",
        "        # Initialize Chroma vector store\n",
        "        self.vectordb = Chroma(\n",
        "            persist_directory=self.persist_directory,\n",
        "            embedding_function=self.embedding\n",
        "        )\n",
        "\n",
        "    def clear_vector_store(self):\n",
        "        # Remove old database files if any\n",
        "        os.system('rm -rf ./docs/chroma')\n",
        "\n",
        "    def create_vector_store_from_splits(self, splits):\n",
        "        if not self.embedding:\n",
        "            raise ValueError(\"Embedding function not initialized.\")\n",
        "        self.vectordb = Chroma.from_texts(splits, embedding=OpenAIEmbeddings())\n",
        "        return self.vectordb\n",
        "\n",
        "    def count_documents(self):\n",
        "        if self.vectordb:\n",
        "            return self.vectordb._collection.count()\n",
        "        else:\n",
        "            raise ValueError(\"Vector store not initialized. Please call setup_vector_store first.\")\n",
        "\n",
        "    def similarity_search(self, query, k=5):\n",
        "        if self.vectordb:\n",
        "            return self.vectordb.similarity_search(query, k=k)\n",
        "        else:\n",
        "            raise ValueError(\"Vector store not initialized. Please call setup_vector_store first.\")\n",
        "\n",
        "    def get_relevant_documents(self, query, search_type=\"mmr\", search_kwargs={\"k\": 3}):\n",
        "        if self.vectordb:\n",
        "            retriever = self.vectordb.as_retriever(search_type=search_type, search_kwargs=search_kwargs)\n",
        "            return retriever.get_relevant_documents(query)\n",
        "        else:\n",
        "            raise ValueError(\"Vector store not initialized. Please call setup_vector_store first.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NnvMUdA8FTQA"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wXM6wVr2KIbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the embedding processor\n",
        "processor = EmbeddingProcessor()\n",
        "# Setup vector store\n",
        "processor.setup_vector_store()\n",
        "# Create vector store from splits\n",
        "\n"
      ],
      "metadata": {
        "id": "WkmJVtECFsXP"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of documents:\", processor.count_documents())"
      ],
      "metadata": {
        "id": "fwbfhD2MM1Fr",
        "outputId": "2d3893b3-4c14-44a1-936d-47def2d3fca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processor.clear_vector_store()\n",
        "!rm -rf ./docs/chroma  # remove old database files if any\n",
        "    # Count documents\n",
        "print(\"Number of documents:\", processor.count_documents())"
      ],
      "metadata": {
        "id": "vBR-GPgfKij-",
        "outputId": "f26171d1-f8be-4faf-de72-13fe282dd1da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splits"
      ],
      "metadata": {
        "id": "i6LB-_NSM7Bp",
        "outputId": "b8cfb7ee-8b14-4ad9-ebe5-41c5426c5260",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['InloggenInloggenVoordat je verdergaat naar GoogleWe gebruikencookiesen gegevens voor het volgende:Google-services leveren en onderhoudenUitval bijhouden en bescherming bieden tegen spam, fraude en misbruikDoelgroepbetrokkenheid en sitestatistieken meten om inzicht te krijgen in hoe onze services worden gebruikt en de kwaliteit van die services te verbeterenAls je Alles accepteren kiest, gebruiken we cookies en gegevens ook voor het volgende:Nieuwe services ontwikkelen en verbeterenAdvertenties laten zien en de effectiviteit ervan metenGepersonaliseerde content laten zien (afhankelijk van je instellingen)Gepersonaliseerde advertenties laten zien (afhankelijk van je instellingen)Als je Alles',\n",
              " 'content laten zien (afhankelijk van je instellingen)Gepersonaliseerde advertenties laten zien (afhankelijk van je instellingen)Als je Alles afwijzen kiest, gebruiken we cookies niet voor deze aanvullende doeleinden.Niet-gepersonaliseerde content wordt benvloed door factoren zoals de content die je op dat moment bekijkt, activiteit in je actieve zoeksessie en je locatie. Niet-gepersonaliseerde advertenties worden benvloed door de content die je op dat moment bekijkt en je algemene locatie. Gepersonaliseerde content en advertenties kunnen ook relevantere resultaten, aanbevelingen en op jou toegespitste advertenties omvatten die zijn gebaseerd op eerdere activiteit van deze browser, zoals',\n",
              " 'relevantere resultaten, aanbevelingen en op jou toegespitste advertenties omvatten die zijn gebaseerd op eerdere activiteit van deze browser, zoals uitgevoerde Google-zoekopdrachten. We gebruiken cookies en gegevens ook om te zorgen dat de functionaliteit geschikt is voor je leeftijd, als dit relevant is.Selecteer Meer opties om meer informatie te bekijken, waaronder informatie over hoe je je privacyinstellingen beheert. Je kunt ook altijd naar g.co/privacytools gaan.Meer optiesAfrikaansazrbaycanbosanskicataletinaCymraegDanskDeutscheestiEnglish(United Kingdom)English(United',\n",
              " 'ook altijd naar g.co/privacytools gaan.Meer optiesAfrikaansazrbaycanbosanskicataletinaCymraegDanskDeutscheestiEnglish(United Kingdom)English(United States)Espaol(Espaa)Espaol(Latinoamrica)euskaraFilipinoFranais(Canada)Franais(France)GaeilgegalegoHrvatskiIndonesiaisiZuluslenskaItalianoKiswahililatvieulietuvimagyarMelayuNederlandsnorskozbekpolskiPortugus(Brasil)Portugus(Portugal)romnshqipSloveninasloveninasrpski (latinica)SuomiSvenskaTing VitTrke ()PrivacybeleidServicevoorwaarden',\n",
              " '***Title: Apotheke 3-Wick Candles Collection\\nDescription: Captivating Fragrance: Transform any living space with the unforgettable scent of Charcoal 3-Wick Candle from APOTHEKE. Our candles are hand poured and made with a proprietary blend of essential and perfume-grade oils for a long-lasting fragrance. Each 26 oz candle burns for approximately 120 - 1...\\nURL: https://www.amazon.com/dp/B07PMY9PK6/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B07PMY9PK6 \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/61yZbIMhvVL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/Scented-Candles-Home-Soy-Wax-Jar-Candle/dp/B07PMY9PK6\\n ***Title: MSRP/MAP Policy',\n",
              " 'link: https://www.amazon.com/Scented-Candles-Home-Soy-Wax-Jar-Candle/dp/B07PMY9PK6\\n ***Title: MSRP/MAP Policy\\nDescription: In order to preserve its reputation for providing customers with high value products and strong after-sales support, and to further enhance the APOTHEKE brand image and its competitiveness in the marketplace, APOTHEKE is unilaterally instituting a policy of minimum advertised price standards for APOTHEKE products.\\nImage URL: http:files/Charcoal2.jpg \\nURL: https://apothekeco.com/pages/msrpmap-policy \\nAvailability: Unknown\\nSite Name: APOTHEKE \\ntype: website \\nimage2: https://hello.zonos.com/images/flags/US.png \\nlink: https://apothekeco.com/pages/msrpmap-policy',\n",
              " 'Site Name: APOTHEKE \\ntype: website \\nimage2: https://hello.zonos.com/images/flags/US.png \\nlink: https://apothekeco.com/pages/msrpmap-policy\\n ***Title: APOTHEKE Market Collection Luxury Scented 3-Wick Jar Candle, Purple Basil, 32 oz - Basil, Ginger Lime & Lily of The Valley Scent, Strong Fragrance, Aromatherapy, Long Lasting, Hand Poured in USA, Soy\\nDescription: APOTHEKE Luxury Jar Candles Purple Basil - 32 Ounce 3-Wick Jar Candle SCENT PROFILE: Purple basil, spicy ginger and juicy lime zest mingle with hints of lily of the valley Our candles are hand-poured with perfume-grade fragrance oils and a high quality soy wax blend. Each scent is formulated with...',\n",
              " 'URL: https://www.amazon.com/dp/B09RTPD6ZN/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B09RTPD6ZN \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/618bD-pCyRL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/APOTHEKE-Market-Collection-Luxury-Scented/dp/B09RTPD6ZN']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(splits)"
      ],
      "metadata": {
        "id": "uCqFmKUlM-qu",
        "outputId": "e1164b64-e201-41fe-e497-b2f2f00e1c92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processor.create_vector_store_from_splits(splits)\n",
        "    # Count documents\n",
        "print(\"Number of documents:\", processor.count_documents())"
      ],
      "metadata": {
        "id": "wxD7qV0wKhiR",
        "outputId": "33319731-1d5f-4dad-c448-fad6037936b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "    # Perform similarity search\n",
        "query = \"Apotheke 3-Wick Candles Collection charcoal UPC ASIN\"\n",
        "print(\"Similar documents:\", processor.similarity_search(query, k=5))\n",
        "\n",
        "    # Get relevant documents\n",
        "print(\"Relevant documents:\", processor.get_relevant_documents(query))"
      ],
      "metadata": {
        "id": "pi-y9miQJlPD",
        "outputId": "50e66286-1fe7-4aeb-f20e-79eda0241370",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar documents: [Document(page_content='***Title: Apotheke 3-Wick Candles Collection\\nDescription: Captivating Fragrance: Transform any living space with the unforgettable scent of Charcoal 3-Wick Candle from APOTHEKE. Our candles are hand poured and made with a proprietary blend of essential and perfume-grade oils for a long-lasting fragrance. Each 26 oz candle burns for approximately 120 - 1...\\nURL: https://www.amazon.com/dp/B07PMY9PK6/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B07PMY9PK6 \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/61yZbIMhvVL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/Scented-Candles-Home-Soy-Wax-Jar-Candle/dp/B07PMY9PK6\\n ***Title: MSRP/MAP Policy'), Document(page_content='***Title: Apotheke 3-Wick Candles Collection\\nDescription: Captivating Fragrance: Transform any living space with the unforgettable scent of Charcoal 3-Wick Candle from APOTHEKE. Our candles are hand poured and made with a proprietary blend of essential and perfume-grade oils for a long-lasting fragrance. Each 26 oz candle burns for approximately 120 - 1...\\nURL: https://www.amazon.com/dp/B07PMY9PK6/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B07PMY9PK6 \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/61yZbIMhvVL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/Scented-Candles-Home-Soy-Wax-Jar-Candle/dp/B07PMY9PK6\\n ***Title: MSRP/MAP Policy'), Document(page_content='***Title: Apotheke 3-Wick Candles Collection\\nDescription: Captivating Fragrance: Transform any living space with the unforgettable scent of Charcoal 3-Wick Candle from APOTHEKE. Our candles are hand poured and made with a proprietary blend of essential and perfume-grade oils for a long-lasting fragrance. Each 26 oz candle burns for approximately 120 - 1...\\nURL: https://www.amazon.com/dp/B07PMY9PK6/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B07PMY9PK6 \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/61yZbIMhvVL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/Scented-Candles-Home-Soy-Wax-Jar-Candle/dp/B07PMY9PK6\\n ***Title: MSRP/MAP Policy'), Document(page_content='***Title: Apotheke 3-Wick Candles Collection\\nDescription: Captivating Fragrance: Transform any living space with the unforgettable scent of Charcoal 3-Wick Candle from APOTHEKE. Our candles are hand poured and made with a proprietary blend of essential and perfume-grade oils for a long-lasting fragrance. Each 26 oz candle burns for approximately 120 - 1...\\nURL: https://www.amazon.com/dp/B07PMY9PK6/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B07PMY9PK6 \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/61yZbIMhvVL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/Scented-Candles-Home-Soy-Wax-Jar-Candle/dp/B07PMY9PK6\\n ***Title: MSRP/MAP Policy'), Document(page_content='***Title: Apotheke 3-Wick Candles Collection\\nDescription: Captivating Fragrance: Transform any living space with the unforgettable scent of Charcoal 3-Wick Candle from APOTHEKE. Our candles are hand poured and made with a proprietary blend of essential and perfume-grade oils for a long-lasting fragrance. Each 26 oz candle burns for approximately 120 - 1...\\nURL: https://www.amazon.com/dp/B07PMY9PK6/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B07PMY9PK6 \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/61yZbIMhvVL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/Scented-Candles-Home-Soy-Wax-Jar-Candle/dp/B07PMY9PK6\\n ***Title: MSRP/MAP Policy')]\n",
            "Relevant documents: [Document(page_content='***Title: Apotheke 3-Wick Candles Collection\\nDescription: Captivating Fragrance: Transform any living space with the unforgettable scent of Charcoal 3-Wick Candle from APOTHEKE. Our candles are hand poured and made with a proprietary blend of essential and perfume-grade oils for a long-lasting fragrance. Each 26 oz candle burns for approximately 120 - 1...\\nURL: https://www.amazon.com/dp/B07PMY9PK6/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B07PMY9PK6 \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/61yZbIMhvVL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/Scented-Candles-Home-Soy-Wax-Jar-Candle/dp/B07PMY9PK6\\n ***Title: MSRP/MAP Policy'), Document(page_content='URL: https://www.amazon.com/dp/B09RTPD6ZN/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B09RTPD6ZN \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/618bD-pCyRL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/APOTHEKE-Market-Collection-Luxury-Scented/dp/B09RTPD6ZN'), Document(page_content='Site Name: APOTHEKE \\ntype: website \\nimage2: https://hello.zonos.com/images/flags/US.png \\nlink: https://apothekeco.com/pages/msrpmap-policy\\n ***Title: APOTHEKE Market Collection Luxury Scented 3-Wick Jar Candle, Purple Basil, 32 oz - Basil, Ginger Lime & Lily of The Valley Scent, Strong Fragrance, Aromatherapy, Long Lasting, Hand Poured in USA, Soy\\nDescription: APOTHEKE Luxury Jar Candles Purple Basil - 32 Ounce 3-Wick Jar Candle SCENT PROFILE: Purple basil, spicy ginger and juicy lime zest mingle with hints of lily of the valley Our candles are hand-poured with perfume-grade fragrance oils and a high quality soy wax blend. Each scent is formulated with...')]\n"
          ]
        }
      ]
    }
  ]
}