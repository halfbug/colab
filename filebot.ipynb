{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/halfbug/colab/blob/main/filebot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN-9yTlYtFnI"
      },
      "source": [
        "# Installation and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIcTejQ9eANF",
        "outputId": "d900e7e5-2b83-42ed-bd4f-ab90e32eeed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.14.3\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
            "  Downloading langchain_core-0.1.36-py3-none-any.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.9/273.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.37-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.36 langchain-text-splitters-0.0.1 langsmith-0.1.37 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.1-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.1.36)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.14.3)\n",
            "Collecting tiktoken<1,>=0.5.2 (from langchain-openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (0.1.37)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.10.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.0.7)\n",
            "Installing collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.1.1 tiktoken-0.6.0\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.1.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.4)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.10.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.0)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.7)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=43a6d824f224a3f4d6374024d0ad9a274947be5ce5cdf1424a46439fd5da1419\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, uvicorn, python-dotenv, pulsar-client, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, importlib-metadata, humanfriendly, httptools, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.110.0 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-7.0.0 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.17.1 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 overrides-7.7.0 posthog-3.5.0 pulsar-client-3.4.0 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.36.3 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "try:\n",
        "  import openai\n",
        "  from langchain_openai import ChatOpenAI\n",
        "except:\n",
        "    !pip install openai\n",
        "    !pip install langchain\n",
        "    !pip install langchain-openai\n",
        "    !pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BkDjE2AieNra"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "# llm = ChatOpenAI(openai_api_key=os.getenv('OPENAI_API_KEY'))\n",
        "openai.api_key  = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtNkHmw77N5Q",
        "outputId": "85f8cd94-dcef-4687-9e99-3e178bd16913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-3.5-turbo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 10, 'total_tokens': 19}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "import datetime\n",
        "current_date = datetime.datetime.now().date()\n",
        "# llm_name = \"gpt-4\"\n",
        "if current_date < datetime.date(2023, 9, 2):\n",
        "    llm_name = \"gpt-3.5-turbo-0301\"\n",
        "else:\n",
        "    llm_name = \"gpt-3.5-turbo\"\n",
        "print(llm_name)\n",
        "llm = ChatOpenAI(model_name=llm_name, temperature=0)\n",
        "llm.invoke(\"Hello world!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgKOubuG7mj_"
      },
      "source": [
        "# ExcelProcessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bJCLz2UAjiqN"
      },
      "outputs": [],
      "source": [
        "class ExcelProcessor:\n",
        "    def __init__(self, file_path=None, sheet_id=None, sheet_name=\"Excel file\"):\n",
        "        # Example usage for opening a Google Sheet:\n",
        "        # sheet_id = '1M8mauGQDZVbXpwQPAlfrKc2suVqtdB5k'\n",
        "        # sheet_name = \"LevelGuide\"\n",
        "        # processor = ExcelProcessor(sheet_id=sheet_id, sheet_name=sheet_name)\n",
        "\n",
        "        if file_path:\n",
        "            self.df = pd.read_excel(file_path)\n",
        "        elif sheet_id and sheet_name:\n",
        "            url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "            self.df = pd.read_csv(url)\n",
        "        else:\n",
        "            raise ValueError(\"Either provide a file path or Google Sheet ID and sheet name.\")\n",
        "        # self.logger = Logger(__name__).logger\n",
        "\n",
        "    def get_empty_columns_names(self):\n",
        "        empty_columns = self.df.columns[self.df.isnull().any()].tolist()\n",
        "        return empty_columns\n",
        "\n",
        "    def get_filled_columns_names(self):\n",
        "        filled_columns = self.df.columns[self.df.notnull().any()].tolist()\n",
        "        return filled_columns\n",
        "\n",
        "    def list_columns_with_values(self,num_columns=None):\n",
        "        non_empty_columns = self.df.columns[self.df.notnull().any()].tolist()\n",
        "        filtered_df = self.df[non_empty_columns]\n",
        "        if num_columns:\n",
        "            return filtered_df.values[:, :num_columns].tolist()\n",
        "        else:\n",
        "            return filtered_df.values.tolist()\n",
        "        return columns_with_values\n",
        "\n",
        "    def get_all_rows(self):\n",
        "        return self.df.values.tolist()\n",
        "\n",
        "    def get_all_rows_values(self):\n",
        "        non_empty_columns = self.df.columns[self.df.notnull().any()].tolist()\n",
        "        filtered_df = self.df[non_empty_columns]\n",
        "        return filtered_df.values.tolist()\n",
        "\n",
        "    def get_total_rows_columns(self):\n",
        "        total_rows, total_columns = self.df.shape\n",
        "        self.logger.info(\"get total rows and columns in the sheet\")\n",
        "        return total_rows, total_columns\n",
        "        # Example usage to get total rows and columns in the sheet\n",
        "        # total_rows, total_columns = processor.get_total_rows_columns()\n",
        "        # print(\"Total rows:\", total_rows)\n",
        "        # print(\"Total columns:\", total_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wR9oYhMdlTJn"
      },
      "outputs": [],
      "source": [
        "sheet_id = '1M8mauGQDZVbXpwQPAlfrKc2suVqtdB5k'\n",
        "sheet_name = \"LevelGuide\"\n",
        "processor = ExcelProcessor(sheet_id=sheet_id, sheet_name=sheet_name)\n",
        "\n",
        "# print(\"Empty columns:\", processor.get_empty_columns_names())\n",
        "\n",
        "# # print(\"Columns with values:\", processor.get_filled_columns_names()[ :3])\n",
        "# print(\"Columns with values:\", ' '.join(processor.get_filled_columns_names()))\n",
        "\n",
        "# print(\"All rows of the sheet:\")\n",
        "# all_rows = processor.get_all_rows_values()\n",
        "# for row in all_rows:\n",
        "#     # print(row)\n",
        "#     row_str = \", \".join(map(str, row))\n",
        "#     # print(row_str)\n",
        "\n",
        "# # Example usage to get total rows and columns in the sheet\n",
        "# total_rows, total_columns = processor.get_total_rows_columns()\n",
        "# print(\"Total rows:\", total_rows)\n",
        "# print(\"Total columns:\", total_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QvNBIDjsABT"
      },
      "source": [
        "# **Sheet Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "vLVqjTvzh1pz",
        "outputId": "2f43a194-82db-4222-db84-cf408469747d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                join  Hemster ID  \\\n",
              "0     55718 194900722053 30F1GCDS2L 001 Michael Kors       55718   \n",
              "1    55740 196163322728 30S2G9HM6L 1999 Michael Kors       55740   \n",
              "2  55760 196163134963 30S2SCDT3L chambray Michael...       55760   \n",
              "3        55770 193144528056 MM7W775 110 Michael Kors       55770   \n",
              "4  55858 196163135120 30S2SGRL8L CHAMBRAY Michael...       55858   \n",
              "5     55862 196237052124 MU2814EF4C 671 Michael Kors       55862   \n",
              "6  55865 196163502335 30F2GANM2L DEEP ORANGE Mich...       55865   \n",
              "7    55916 196163140940 32T9GF6T3B 2623 Michael Kors       55916   \n",
              "8     56006 196237046857 MU281CQ6KW 250 Michael Kors       56006   \n",
              "9     56003 196239394963 CU2510NFV4 100 Michael Kors       56003   \n",
              "\n",
              "         MK SKU             Description Grade            Garment Type  \\\n",
              "0  194900722053          30F1GCDS2L 001     a                    Bags   \n",
              "1  196163322728         30S2G9HM6L 1999     a                    Bags   \n",
              "2  196163134963     30S2SCDT3L chambray     a                    Bags   \n",
              "3  193144528056             MM7W775 110     a                 Scarves   \n",
              "4  196163135120     30S2SGRL8L CHAMBRAY     a                    Bags   \n",
              "5  196237052124          MU2814EF4C 671     a  Basic Sleeveless Dress   \n",
              "6  196163502335  30F2GANM2L DEEP ORANGE     a                    Bags   \n",
              "7  196163140940         32T9GF6T3B 2623     a                  Wallet   \n",
              "8  196237046857          MU281CQ6KW 250     a     Basic Sleeved Dress   \n",
              "9  196239394963          CU2510NFV4 100     a             Sleeved Top   \n",
              "\n",
              "  Category Type     MSRP  brand   image  Sold on amazon  color  Amazon price  \\\n",
              "0     Accessory  $200.00     NaN    NaN             NaN    NaN           NaN   \n",
              "1     Accessory  $138.00     NaN    NaN             NaN    NaN           NaN   \n",
              "2     Accessory  $150.00     NaN    NaN             NaN    NaN           NaN   \n",
              "3     Accessory  $100.00     NaN    NaN             NaN    NaN           NaN   \n",
              "4     Accessory  $250.00     NaN    NaN             NaN    NaN           NaN   \n",
              "5       Apparel  $255.00     NaN    NaN             NaN    NaN           NaN   \n",
              "6     Accessory  $200.00     NaN    NaN             NaN    NaN           NaN   \n",
              "7     Accessory   $60.00     NaN    NaN             NaN    NaN           NaN   \n",
              "8       Apparel  $255.00     NaN    NaN             NaN    NaN           NaN   \n",
              "9       Apparel   $80.00     NaN    NaN             NaN    NaN           NaN   \n",
              "\n",
              "   ASIN  UPC  \n",
              "0   NaN  NaN  \n",
              "1   NaN  NaN  \n",
              "2   NaN  NaN  \n",
              "3   NaN  NaN  \n",
              "4   NaN  NaN  \n",
              "5   NaN  NaN  \n",
              "6   NaN  NaN  \n",
              "7   NaN  NaN  \n",
              "8   NaN  NaN  \n",
              "9   NaN  NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f59c7448-62c2-411b-a56a-11e356c478b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>join</th>\n",
              "      <th>Hemster ID</th>\n",
              "      <th>MK SKU</th>\n",
              "      <th>Description</th>\n",
              "      <th>Grade</th>\n",
              "      <th>Garment Type</th>\n",
              "      <th>Category Type</th>\n",
              "      <th>MSRP</th>\n",
              "      <th>brand</th>\n",
              "      <th>image</th>\n",
              "      <th>Sold on amazon</th>\n",
              "      <th>color</th>\n",
              "      <th>Amazon price</th>\n",
              "      <th>ASIN</th>\n",
              "      <th>UPC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>55718 194900722053 30F1GCDS2L 001 Michael Kors</td>\n",
              "      <td>55718</td>\n",
              "      <td>194900722053</td>\n",
              "      <td>30F1GCDS2L 001</td>\n",
              "      <td>a</td>\n",
              "      <td>Bags</td>\n",
              "      <td>Accessory</td>\n",
              "      <td>$200.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55740 196163322728 30S2G9HM6L 1999 Michael Kors</td>\n",
              "      <td>55740</td>\n",
              "      <td>196163322728</td>\n",
              "      <td>30S2G9HM6L 1999</td>\n",
              "      <td>a</td>\n",
              "      <td>Bags</td>\n",
              "      <td>Accessory</td>\n",
              "      <td>$138.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>55760 196163134963 30S2SCDT3L chambray Michael...</td>\n",
              "      <td>55760</td>\n",
              "      <td>196163134963</td>\n",
              "      <td>30S2SCDT3L chambray</td>\n",
              "      <td>a</td>\n",
              "      <td>Bags</td>\n",
              "      <td>Accessory</td>\n",
              "      <td>$150.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55770 193144528056 MM7W775 110 Michael Kors</td>\n",
              "      <td>55770</td>\n",
              "      <td>193144528056</td>\n",
              "      <td>MM7W775 110</td>\n",
              "      <td>a</td>\n",
              "      <td>Scarves</td>\n",
              "      <td>Accessory</td>\n",
              "      <td>$100.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55858 196163135120 30S2SGRL8L CHAMBRAY Michael...</td>\n",
              "      <td>55858</td>\n",
              "      <td>196163135120</td>\n",
              "      <td>30S2SGRL8L CHAMBRAY</td>\n",
              "      <td>a</td>\n",
              "      <td>Bags</td>\n",
              "      <td>Accessory</td>\n",
              "      <td>$250.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>55862 196237052124 MU2814EF4C 671 Michael Kors</td>\n",
              "      <td>55862</td>\n",
              "      <td>196237052124</td>\n",
              "      <td>MU2814EF4C 671</td>\n",
              "      <td>a</td>\n",
              "      <td>Basic Sleeveless Dress</td>\n",
              "      <td>Apparel</td>\n",
              "      <td>$255.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>55865 196163502335 30F2GANM2L DEEP ORANGE Mich...</td>\n",
              "      <td>55865</td>\n",
              "      <td>196163502335</td>\n",
              "      <td>30F2GANM2L DEEP ORANGE</td>\n",
              "      <td>a</td>\n",
              "      <td>Bags</td>\n",
              "      <td>Accessory</td>\n",
              "      <td>$200.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>55916 196163140940 32T9GF6T3B 2623 Michael Kors</td>\n",
              "      <td>55916</td>\n",
              "      <td>196163140940</td>\n",
              "      <td>32T9GF6T3B 2623</td>\n",
              "      <td>a</td>\n",
              "      <td>Wallet</td>\n",
              "      <td>Accessory</td>\n",
              "      <td>$60.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>56006 196237046857 MU281CQ6KW 250 Michael Kors</td>\n",
              "      <td>56006</td>\n",
              "      <td>196237046857</td>\n",
              "      <td>MU281CQ6KW 250</td>\n",
              "      <td>a</td>\n",
              "      <td>Basic Sleeved Dress</td>\n",
              "      <td>Apparel</td>\n",
              "      <td>$255.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>56003 196239394963 CU2510NFV4 100 Michael Kors</td>\n",
              "      <td>56003</td>\n",
              "      <td>196239394963</td>\n",
              "      <td>CU2510NFV4 100</td>\n",
              "      <td>a</td>\n",
              "      <td>Sleeved Top</td>\n",
              "      <td>Apparel</td>\n",
              "      <td>$80.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f59c7448-62c2-411b-a56a-11e356c478b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f59c7448-62c2-411b-a56a-11e356c478b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f59c7448-62c2-411b-a56a-11e356c478b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-66535958-ee01-4ca3-b3f6-36069060c47d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66535958-ee01-4ca3-b3f6-36069060c47d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-66535958-ee01-4ca3-b3f6-36069060c47d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"processor\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"join\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"56006 196237046857 MU281CQ6KW 250 Michael Kors\",\n          \"55740 196163322728 30S2G9HM6L 1999 Michael Kors\",\n          \"55862 196237052124 MU2814EF4C 671 Michael Kors\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hemster ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 103,\n        \"min\": 55718,\n        \"max\": 56006,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          56006,\n          55740,\n          55862\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MK SKU\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1004268840,\n        \"min\": 193144528056,\n        \"max\": 196239394963,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          196237046857,\n          196163322728,\n          196237052124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"MU281CQ6KW 250\",\n          \"30S2G9HM6L 1999\",\n          \"MU2814EF4C 671\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Grade\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Garment Type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Bags\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Apparel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MSRP\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"$138.00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"brand \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sold on amazon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"color\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Amazon price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASIN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UPC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "processor.df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Fy2hkH9WADbI"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableMap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CWys22wJAwb6"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "Your task as an Excel file analyst is to analyze provided data and identify any columns that are empty or partially empty.\n",
        "If there are such columns, your goal is to generate search terms based on the existing data to help complete these columns.\n",
        "If it's not possible to fill in the missing values for the columns, you should indicate that.\n",
        "Finally, if it's feasible to provide values for the columns, you should do so.\n",
        "\n",
        "Data : {file_data}\n",
        "\n",
        "Your answer should be provided in JSON format with the following structure:\n",
        "\n",
        "\"message\": Message for the user, describing the steps you've taken so far.\n",
        "\"empty_columns\": List of column names that are empty or partially empty.\n",
        "\"search_queries\": List of search queries uniquely describing each row, for all 10 rows. These queries can be used to search the web for filling the empty columns so keep them as short as possible.\n",
        "\"column_values\": Generate a list of dictionaries, each representing a row. Include all empty column names as keys and suggest values if they can be inferred from the given data; avoid guessing, If uncertain, denote as \"N/A\" instead of guessing.\n",
        "\n",
        "Note : donot make hellocination if you dont now just write N/A\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-cdw-6OtA4YE"
      },
      "outputs": [],
      "source": [
        "model = llm\n",
        "output_parser = StrOutputParser()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DFu7PmQoBBEH"
      },
      "outputs": [],
      "source": [
        "chain = prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRdev59gf5fB",
        "outputId": "c0663ea0-8bc9-459b-a928-9fb291c535a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"message\": \"I have analyzed the provided data and identified the empty columns. I have generated search queries based on the existing data to help complete these columns.\",\n",
            "    \"empty_columns\": [\"brand\", \"image\", \"Sold on amazon\", \"color\", \"Amazon price\", \"ASIN\", \"UPC\"],\n",
            "    \"search_queries\": [\n",
            "        \"Michael Kors 30F1GCDS2L 001\",\n",
            "        \"Michael Kors 30S2G9HM6L 1999\",\n",
            "        \"Michael Kors 30S2SCDT3L chambray\",\n",
            "        \"Michael Kors MM7W775 110\",\n",
            "        \"Michael Kors 30S2SGRL8L CHAMBRAY\",\n",
            "        \"Michael Kors MU2814EF4C 671\",\n",
            "        \"Michael Kors 30F2GANM2L DEEP ORANGE\",\n",
            "        \"Michael Kors 32T9GF6T3B 2623\",\n",
            "        \"Michael Kors MU281CQ6KW 250\",\n",
            "        \"Michael Kors CU2510NFV4 100\"\n",
            "    ],\n",
            "    \"column_values\": [\n",
            "        {\n",
            "            \"brand\": \"Michael Kors\",\n",
            "            \"image\": \"N/A\",\n",
            "            \"Sold on amazon\": \"N/A\",\n",
            "            \"color\": \"N/A\",\n",
            "            \"Amazon price\": \"N/A\",\n",
            "            \"ASIN\": \"N/A\",\n",
            "            \"UPC\": \"N/A\"\n",
            "        },\n",
            "        {\n",
            "            \"brand\": \"Michael Kors\",\n",
            "            \"image\": \"N/A\",\n",
            "            \"Sold on amazon\": \"N/A\",\n",
            "            \"color\": \"N/A\",\n",
            "            \"Amazon price\": \"N/A\",\n",
            "            \"ASIN\": \"N/A\",\n",
            "            \"UPC\": \"N/A\"\n",
            "        },\n",
            "        {\n",
            "            \"brand\": \"Michael Kors\",\n",
            "            \"image\": \"N/A\",\n",
            "            \"Sold on amazon\": \"N/A\",\n",
            "            \"color\": \"N/A\",\n",
            "            \"Amazon price\": \"N/A\",\n",
            "            \"ASIN\": \"N/A\",\n",
            "            \"UPC\": \"N/A\"\n",
            "        },\n",
            "        {\n",
            "            \"brand\": \"Michael Kors\",\n",
            "            \"image\": \"N/A\",\n",
            "            \"Sold on amazon\": \"N/A\",\n",
            "            \"color\": \"N/A\",\n",
            "            \"Amazon price\": \"N/A\",\n",
            "            \"ASIN\": \"N/A\",\n",
            "            \"UPC\": \"N/A\"\n",
            "        },\n",
            "        {\n",
            "            \"brand\": \"Michael Kors\",\n",
            "            \"image\": \"N/A\",\n",
            "            \"Sold on amazon\": \"N/A\",\n",
            "            \"color\": \"N/A\",\n",
            "            \"Amazon price\": \"N/A\",\n",
            "            \"ASIN\": \"N/A\",\n",
            "            \"UPC\": \"N/A\"\n",
            "        },\n",
            "        {\n",
            "            \"brand\": \"Michael Kors\",\n",
            "            \"image\": \"N/A\",\n",
            "            \"Sold on amazon\": \"N/A\",\n",
            "            \"color\": \"N/A\",\n",
            "            \"Amazon price\": \"N/A\",\n",
            "            \"ASIN\": \"N/A\",\n",
            "            \"UPC\": \"N/A\"\n",
            "        },\n",
            "        {\n",
            "            \"brand\": \"Michael Kors\",\n",
            "            \"image\": \"N/A\",\n",
            "            \"Sold on amazon\": \"N/A\",\n",
            "            \"color\": \"N/A\",\n",
            "            \"Amazon price\": \"N/A\",\n",
            "            \"ASIN\": \"N/A\",\n",
            "            \"UPC\": \"N/A\"\n",
            "        },\n",
            "        {\n",
            "            \"brand\": \"Michael Kors\",\n",
            "            \"image\": \"N/A\",\n",
            "            \"Sold on amazon\": \"N/A\",\n",
            "            \"color\": \"N/A\",\n",
            "            \"Amazon price\": \"N/A\",\n",
            "            \"ASIN\": \"N/A\",\n",
            "            \"UPC\": \"N/A\"\n",
            "        },\n",
            "        {\n",
            "            \"brand\": \"Michael Kors\",\n",
            "            \"image\": \"N/A\",\n",
            "            \"Sold on amazon\": \"N/A\",\n",
            "            \"color\": \"N/A\",\n",
            "            \"Amazon price\": \"N/A\",\n",
            "            \"ASIN\": \"N/A\",\n",
            "            \"UPC\": \"N/A\"\n",
            "        },\n",
            "        {\n",
            "            \"brand\": \"Michael Kors\",\n",
            "            \"image\": \"N/A\",\n",
            "            \"Sold on amazon\": \"N/A\",\n",
            "            \"color\": \"N/A\",\n",
            "            \"Amazon price\": \"N/A\",\n",
            "            \"ASIN\": \"N/A\",\n",
            "            \"UPC\": \"N/A\"\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "sheet_analysis= chain.invoke({\"file_data\": processor.df.head(10)})\n",
        "print(sheet_analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "L5EMeMDHcCOz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "sheet_analysis=json.loads(sheet_analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3urt4NebXSQ",
        "outputId": "52bdfc4b-5081-4a13-9505-b005ef71e6de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty columns: ['brand', 'image', 'Sold on amazon', 'color', 'Amazon price', 'ASIN', 'UPC']\n",
            "Search query at index 0: Michael Kors 30F1GCDS2L 001\n",
            "All search queries: ['Michael Kors 30F1GCDS2L 001', 'Michael Kors 30S2G9HM6L 1999', 'Michael Kors 30S2SCDT3L chambray', 'Michael Kors MM7W775 110', 'Michael Kors 30S2SGRL8L CHAMBRAY', 'Michael Kors MU2814EF4C 671', 'Michael Kors 30F2GANM2L DEEP ORANGE', 'Michael Kors 32T9GF6T3B 2623', 'Michael Kors MU281CQ6KW 250', 'Michael Kors CU2510NFV4 100']\n",
            "All rows column values: [{'brand': 'Michael Kors', 'image': 'N/A', 'Sold on amazon': 'N/A', 'color': 'N/A', 'Amazon price': 'N/A', 'ASIN': 'N/A', 'UPC': 'N/A'}, {'brand': 'Michael Kors', 'image': 'N/A', 'Sold on amazon': 'N/A', 'color': 'N/A', 'Amazon price': 'N/A', 'ASIN': 'N/A', 'UPC': 'N/A'}, {'brand': 'Michael Kors', 'image': 'N/A', 'Sold on amazon': 'N/A', 'color': 'N/A', 'Amazon price': 'N/A', 'ASIN': 'N/A', 'UPC': 'N/A'}, {'brand': 'Michael Kors', 'image': 'N/A', 'Sold on amazon': 'N/A', 'color': 'N/A', 'Amazon price': 'N/A', 'ASIN': 'N/A', 'UPC': 'N/A'}, {'brand': 'Michael Kors', 'image': 'N/A', 'Sold on amazon': 'N/A', 'color': 'N/A', 'Amazon price': 'N/A', 'ASIN': 'N/A', 'UPC': 'N/A'}, {'brand': 'Michael Kors', 'image': 'N/A', 'Sold on amazon': 'N/A', 'color': 'N/A', 'Amazon price': 'N/A', 'ASIN': 'N/A', 'UPC': 'N/A'}, {'brand': 'Michael Kors', 'image': 'N/A', 'Sold on amazon': 'N/A', 'color': 'N/A', 'Amazon price': 'N/A', 'ASIN': 'N/A', 'UPC': 'N/A'}, {'brand': 'Michael Kors', 'image': 'N/A', 'Sold on amazon': 'N/A', 'color': 'N/A', 'Amazon price': 'N/A', 'ASIN': 'N/A', 'UPC': 'N/A'}, {'brand': 'Michael Kors', 'image': 'N/A', 'Sold on amazon': 'N/A', 'color': 'N/A', 'Amazon price': 'N/A', 'ASIN': 'N/A', 'UPC': 'N/A'}, {'brand': 'Michael Kors', 'image': 'N/A', 'Sold on amazon': 'N/A', 'color': 'N/A', 'Amazon price': 'N/A', 'ASIN': 'N/A', 'UPC': 'N/A'}]\n",
            "Column values at index 0: {'brand': 'Michael Kors', 'image': 'N/A', 'Sold on amazon': 'N/A', 'color': 'N/A', 'Amazon price': 'N/A', 'ASIN': 'N/A', 'UPC': 'N/A'}\n"
          ]
        }
      ],
      "source": [
        "class SheetAnalysis:\n",
        "    def __init__(self, data):\n",
        "        self.message = data.get(\"message\")\n",
        "        self.empty_columns = data.get(\"empty_columns\")\n",
        "        self.search_queries = data.get(\"search_queries\")\n",
        "        self.column_values = data.get(\"column_values\")\n",
        "\n",
        "    def get_empty_columns(self):\n",
        "        return self.empty_columns\n",
        "\n",
        "    def get_search_query_at_index(self, index):\n",
        "        if 0 <= index < len(self.search_queries):\n",
        "            return self.search_queries[index]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def get_all_search_queries(self):\n",
        "        return self.search_queries\n",
        "\n",
        "    def get_all_rows_column_values(self):\n",
        "        return self.column_values\n",
        "\n",
        "    def get_column_values_at_index(self, index):\n",
        "        if 0 <= index < len(self.column_values):\n",
        "            return self.column_values[index]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "\n",
        "\n",
        "analysis = SheetAnalysis(sheet_analysis)\n",
        "\n",
        "# Example usage\n",
        "print(\"Empty columns:\", analysis.get_empty_columns())\n",
        "print(\"Search query at index 0:\", analysis.get_search_query_at_index(0))\n",
        "print(\"All search queries:\", analysis.get_all_search_queries())\n",
        "print(\"All rows column values:\", analysis.get_all_rows_column_values())\n",
        "print(\"Column values at index 0:\", analysis.get_column_values_at_index(0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SyxoTcOUPmW"
      },
      "source": [
        "#  **Search Web**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ7dIU4G7dDQ"
      },
      "source": [
        "# HelperText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVrf2YGm3aQp",
        "outputId": "4d502eac-155d-4baa-9cd0-2120f1227129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatted string: Your input string \n",
            "Cleaned string: Your input string with code\n"
          ]
        }
      ],
      "source": [
        "class HelperText:\n",
        "    @staticmethod\n",
        "    def format_string(input_string):\n",
        "        formatted_string = \"\"\n",
        "\n",
        "        # Split the input string into separate lines\n",
        "        lines = input_string.split('\\n')\n",
        "\n",
        "        # Iterate through each line\n",
        "        for line in lines:\n",
        "            # Check if the line contains a colon ':'\n",
        "            if ':' in line:\n",
        "                # Split the line into key and value based on the colon ':'\n",
        "                key, value = line.split(':', 1)\n",
        "                # Format the key and value and add them to the formatted string\n",
        "                formatted_string += f\"{key.strip()}: {value.strip()} \"\n",
        "            else:\n",
        "                # If the line does not contain a colon, add it as is to the formatted string\n",
        "                formatted_string += f\"{line.strip()} \"\n",
        "\n",
        "        return formatted_string\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def clear_code(input_string):\n",
        "        string_encode = input_string.encode(\"ascii\", \"ignore\")\n",
        "        input_string = string_encode.decode()\n",
        "        return(input_string)\n",
        "\n",
        "# Example usage:\n",
        "helper = HelperText()\n",
        "\n",
        "# Format a string\n",
        "formatted_string = helper.format_string(\"Your input string\")\n",
        "print(\"Formatted string:\", formatted_string)\n",
        "\n",
        "# Clear code from a string\n",
        "cleaned_string = helper.clear_code(\"Your input string with code\")\n",
        "print(\"Cleaned string:\", cleaned_string)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG2x1i3j7TL0"
      },
      "source": [
        "# WebScraper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "EM4eSJq0m6CT",
        "outputId": "f8b9c046-0466-449a-9edd-58655f27d838"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GooglePlease clickhereif you are not redirected within a few seconds.AllImagesShoppingBooksMapsVideosNewsSearch toolsAny timeAny timePast hourPast 24 hoursPast weekPast monthPast yearAll resultsAll resultsVerbatimAmazon.com: Apotheke 3-Wick Candles Collectionwww.amazon.com  Scented-Candles-Home-Soy-Wax-Jar-CandleRating4.1(149)$77.02Unit Count, 32 Ounce ; APOTHEKE Apotheke 3-Wick Candles Collection ; Most purchased | Lowest Pricein this set of products ; Highest ratedin this set of products.ImagesView allView all3-Wick Candles | APOTHEKEapothekeco.com  collections  3-wick-candlesSea Salt Grapefruit 3-Wick Candle. 4.8 out of 5 star rating. 4.8. 21 Reviews. $78.00  Quick View  Hinoki Lavender 3-Wick Candle. 5 out of 5 star rating.Missing:images| Show results with:imagesAPOTHEKE Market Collection Luxury Scented 3-Wick Jar Candle ...www.amazon.com  APOTHEKE-Market-Collection-Luxury-ScentedRating4.2(148)$78.00In stockPaying $78 for a candle that is a three wick candle and only one wick is works and you can obviously see there are three little candles just filled with wax...Apotheke 3-Wick Candles Collection - eBaywww.ebay.com  Home & Garden  Candles & Home Fragrance  Candles$106.00Apotheke 3-Wick Candles Collection ; Item Number. 386813950073 ; UPC. 691164538630 ; EAN. 0691164538630 ; Accurate description. 4.6 ; Reasonable shipping cost. 4.9.Missing:images| Show results with:imagesApotheke 3-wick Candle - Alys Gracewww.alysgrace.com  products  apotheke-3-wick-candle$78.00In stockThis 3-Wick Candle fills any space with hours of warm, enticing fragrance. 120 hour approximate burn time Soy wax blend Made in the USA.People also askAre 3 wick candles worth it?How long do Apotheke candles last?What is the most expensive part of a candle?What is an expensive candle?Apotheke 3-Wick Candles Collection Charcoal | eBaywww.ebay.com  Home & Garden  Candles & Home Fragrance  Candles$109.95Apotheke 3-Wick Candles Collection Charcoal ; Quantity. 1 available ; Item Number. 155928752194 ; EAN. 0602573896181 ; MPN. CHAR-CAN-3Wick ; Accurate description.Charcoal 3-Wick Candle - Apothekeapothekeco.com  products  charcoal-3-wick-candleRating4.3(143)$78.00In stockThis 3-Wick Scented Candle is made with a premium soy wax blend and essential and perfume-grade fragrance oils in a chic matte-black glass vessel. The FragranceMissing:priceimagesApotheke Charcoal-Scented 3-Wick Candle + Reviews | Crate & Barrelwww.crateandbarrel.com  ...  Scented Candles & DiffusersRating4.8(133)$78.00In stockThis triple-wick candle fills the room with warm, earthy scent inspired by binchotan charcoal. Infused with essences of cedar wood, sandalwood, smoked amber...Apotheke - Bamboo 3 Wick Candle  thescentshop usthescentshop-us.myshopify.com  products  tss-1551$19.00In stockApotheke - Bamboo 3 Wick Candle. Regular price $19.00.Related searchesApotheke 3 wick candles collection price images usaApotheke 3 wick candles collection price images amazonApotheke Candle SetAPOTHEKE 4 Wick CandleApotheke Charcoal candle reviewAPOTHEKE mystery candleApotheke Santal Rock RoseAPOTHEKE Earl Grey BittersNext >United StatesFrom your IP address-Learn moreSign inSettingsPrivacyTermsDark theme: Off\\n \\n ***Title: Apotheke 3-Wick Candles Collection\\nDescription: Captivating Fragrance: Transform any living space with the unforgettable scent of Charcoal 3-Wick Candle from APOTHEKE. Our candles are hand poured and made with a proprietary blend of essential and perfume-grade oils for a long-lasting fragrance. Each 26 oz candle burns for approximately 120 - 1...\\nURL: https://www.amazon.com/dp/B07PMY9PK6/ref=tsm_1_fb_lk \\nAvailability: in stock\\nASIN: B07PMY9PK6 \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/61yZbIMhvVL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/Scented-Candles-Home-Soy-Wax-Jar-Candle/dp/B07PMY9PK6\\n ***Title: MSRP/MAP Policy\\nDescription: In order to preserve its reputation for providing customers with high value products and strong after-sales support, and to further enhance the APOTHEKE brand image and its competitiveness in the marketplace, APOTHEKE is unilaterally instituting a policy of minimum advertised price standards for APOTHEKE products.\\nImage URL: http:files/Charcoal2.jpg \\nURL: https://apothekeco.com/pages/msrpmap-policy \\nAvailability: Unknown\\nSite Name: APOTHEKE \\ntype: website \\nimage2: https://hello.zonos.com/images/flags/US.png \\nlink: https://apothekeco.com/pages/msrpmap-policy\\n ***Title: APOTHEKE Market Collection Luxury Scented 3-Wick Jar Candle, Purple Basil, 32 oz - Basil, Ginger Lime & Lily of The Valley Scent, Strong Fragrance, Aromatherapy, Long Lasting, Hand Poured in USA, Soy\\nDescription: APOTHEKE Luxury Jar Candles Purple Basil - 32 Ounce 3-Wick Jar Candle SCENT PROFILE: Purple basil, spicy ginger and juicy lime zest mingle with hints of lily of the valley Our candles are hand-poured with perfume-grade fragrance oils and a high quality soy wax blend. Each scent is formulated with...\\nURL: https://www.amazon.com/dp/B09RTPD6ZN/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B09RTPD6ZN \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/618bD-pCyRL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/APOTHEKE-Market-Collection-Luxury-Scented/dp/B09RTPD6ZN'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from googleapiclient.discovery import build\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import userdata\n",
        "\n",
        "class WebScraper:\n",
        "    def __init__(self):\n",
        "        self.base_url = \"https://www.google.com/search?q=\"\n",
        "        self.api_key = userdata.get('GOOGLE_SEARCH_API')\n",
        "        self.service = build(\"customsearch\", \"v1\", developerKey=self.api_key)\n",
        "        # self.logger = Logger(__name__).logger\n",
        "\n",
        "    def google_scraper(self, query):\n",
        "        try:\n",
        "          response = requests.get(self.base_url+query.lower().replace(' ', '+'))\n",
        "          soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "          # find first five link's content\n",
        "          # anchor_tags = soup.find_all('a', href=True)\n",
        "          # hrefs = []\n",
        "          # content = \"\"\n",
        "          # for tag in anchor_tags:\n",
        "          #   href = tag.get('href')\n",
        "          #   if href and href.startswith(\"/url?q=https\") and \"google\" not in href.lower():  # Check if href exists (it might be None)\n",
        "          #     parts = href.split('&', 1)\n",
        "          #     parts = parts[0].split('/url?q=',1)\n",
        "          #     # print(parts)\n",
        "          #     hrefs.append(parts[1])\n",
        "          #     scraped_content = scrape_text(parts[1])\n",
        "          #     content += scraped_content + \"\\n ***\"\n",
        "              # print(scraped_content)\n",
        "          # print(hrefs[:5])\n",
        "\n",
        "\n",
        "\n",
        "          body_content = soup.find('body')  # Find the body tag\n",
        "\n",
        "          if body_content:\n",
        "            # Extract only the text content from the body tag\n",
        "              text_content = body_content.get_text(strip=True)\n",
        "              # print(\"\\033[34m\" + text_content )\n",
        "\n",
        "\n",
        "\n",
        "              return helper.clear_code(text_content)    #format_string(content)\n",
        "        except Exception as e:\n",
        "          print(f\"Error occurred while scraping: {e}\")\n",
        "          return \"No search result found: Unknown\"\n",
        "        self.logger.info(\"Scraping Google search results for: %s\", query)\n",
        "\n",
        "    def scrape_text(self,url):\n",
        "    # Function to scrape the webpage for availability information\n",
        "      try:\n",
        "          response = requests.get(url)\n",
        "          soup = BeautifulSoup(response.content, 'html.parser')\n",
        "          # Search for specific keywords like \"stock availability\" on the webpage\n",
        "\n",
        "          # Step 3: Extract metadata\n",
        "          meta_tags = soup.find_all('meta')\n",
        "          metadata = {}\n",
        "          for tag in meta_tags:\n",
        "              if 'name' in tag.attrs:\n",
        "                  name = tag.attrs['name']\n",
        "                  content = tag.attrs.get('content', '')\n",
        "                  metadata[name] = content\n",
        "              elif 'property' in tag.attrs:  # For OpenGraph metadata\n",
        "                  property = tag.attrs['property']\n",
        "                  content = tag.attrs.get('content', '')\n",
        "                  metadata[property] = content\n",
        "\n",
        "          # Display the metadata\n",
        "          # for key, value in metadata.items():\n",
        "          #     print(f\"{key}: {value}\")\n",
        "\n",
        "          # print( metadata)\n",
        "\n",
        "          meta_tag = self.extract_product_info([metadata])\n",
        "\n",
        "              # Find all link elements with the 'as' attribute set to 'image'\n",
        "          image_links = soup.find_all('link', {'rel': 'preload', 'as': 'image'})\n",
        "\n",
        "          # Extract and print the href attributes\n",
        "          images = ''\n",
        "          for link in image_links:\n",
        "              image_url = link.get('href')\n",
        "              if image_url:\n",
        "                  if image_url.startswith(\"//\"):\n",
        "                    # Add protocol (http assumed):\n",
        "                    image_url= f\"http:{image_url}\"\n",
        "                  images = images +\",\"+ image_url\n",
        "                  # print(image_url)\n",
        "\n",
        "          body_content = soup.find('body')  # Find the body tag\n",
        "          print(body_content)\n",
        "          if body_content:\n",
        "            # Extract only the text content from the body tag\n",
        "              text_content = body_content.get_text(strip=True)\n",
        "\n",
        "              # Search for either \"stock\" or \"stock availability\" in the text content\n",
        "              # print(text_content)\n",
        "              string_encode = text_content.encode(\"ascii\", \"ignore\")\n",
        "              text_content = string_encode.decode()\n",
        "              return text_content + meta_tag + \"Images : \" + images\n",
        "          return f\"Content: Unknown on {url}\"\n",
        "      except Exception as e:\n",
        "          print(f\"Error occurred while scraping: {e}\")\n",
        "          return f\"Content: Unknown on {url}\"\n",
        "\n",
        "    def extract_product_info(self, meta_tags):\n",
        "        # Function to extract product information from meta tags\n",
        "        product_info = \"\"\n",
        "        for meta_tag in meta_tags:\n",
        "            if 'og:title' in meta_tag:\n",
        "                product_info += f\"\\n ***Title: {meta_tag['og:title']}\\n\"\n",
        "            if 'og:description' in meta_tag:\n",
        "                product_info += f\"Description: {meta_tag['og:description']}\\n\"\n",
        "            if 'og:price:amount' in meta_tag and 'og:price:currency' in meta_tag:\n",
        "                product_info += f\"Price: {meta_tag['og:price:amount']} {meta_tag['og:price:currency']}\\n\"\n",
        "            if 'og:image' in meta_tag:\n",
        "                    if len(meta_tag['og:image']) <= 200:  # Check if URL length is less than or equal to 200\n",
        "                        product_info += f\"Image URL: {meta_tag['og:image']} \\n\"\n",
        "            if 'og:url' in meta_tag:\n",
        "                product_info += f\"URL: {meta_tag['og:url']} \\n\"\n",
        "                # Call function to extract availability information\n",
        "                availability_info = self.extract_availability(meta_tag['og:url'])\n",
        "                product_info += f\"{availability_info}\\n\"\n",
        "                # Extract ASIN from URL if it's an Amazon link\n",
        "                asin_match = re.search(r'/dp/(\\w+)', meta_tag['og:url'])\n",
        "                if asin_match:\n",
        "                    product_info += f\"ASIN: {asin_match.group(1)} \\n\"\n",
        "            if 'og:site_name' in meta_tag:\n",
        "                product_info += f\"Site Name: {meta_tag['og:site_name']} \\n\"\n",
        "            if 'og:availability' in meta_tag:\n",
        "                product_info += f\"Availability: {meta_tag['og:availability']} \\n\"\n",
        "            if 'og:type' in meta_tag:\n",
        "                    product_info += f\"type: {meta_tag['og:type']} \\n\"\n",
        "            else:\n",
        "              product_info += f\"type: text \\n\"\n",
        "        return product_info\n",
        "\n",
        "\n",
        "    def extract_availability(self,url):\n",
        "    # Function to scrape the webpage for availability information\n",
        "      try:\n",
        "          response = requests.get(url)\n",
        "          soup = BeautifulSoup(response.content, 'html.parser')\n",
        "          # Search for specific keywords like \"stock availability\" on the webpage\n",
        "\n",
        "          body_content = soup.find('body')  # Find the body tag\n",
        "\n",
        "          if body_content:\n",
        "            # Extract only the text content from the body tag\n",
        "              text_content = body_content.get_text(strip=True)\n",
        "              # Search for either \"stock\" or \"stock availability\" in the text content\n",
        "              # print(text_content)\n",
        "              #  availability_pattern = re.compile(r\"(?:stock|stock|availability|Number\\sof\\sItems\\s*(\\d+)|in\\s*stock|(\\w+)\\s*stock\\s*(\\w+))\", re.IGNORECASE)\n",
        "\n",
        "              availability_pattern = re.compile(r\"(?:stock|stock|availability|in\\s*stock)\", re.IGNORECASE)\n",
        "              match = re.search(availability_pattern, text_content)\n",
        "              # print(match.groups())\n",
        "              if match:\n",
        "                  # print(match.group(0))\n",
        "                  return f\"Availability: {match.group(0).strip()}\"\n",
        "          # If specific keywords not found, return \"Scraped Availability: Unknown\"\n",
        "          return \"Availability: Unknown\"\n",
        "      except Exception as e:\n",
        "          print(f\"Error occurred while scraping: {e}\")\n",
        "          return \"Availability: Unknown\"\n",
        "\n",
        "    def search_google(self,query,num_results):\n",
        "      \"\"\"\n",
        "      Performs a custom search  using the Google Custom Search API.\n",
        "\n",
        "      Args:\n",
        "          query (str): The search query to use.\n",
        "          num_results (int, optional): The number of image search results to return (default: 3).\n",
        "\n",
        "      Returns:\n",
        "          str: A string containing information about the image search results. Each result includes the image URL and its corresponding link.\n",
        "      \"\"\"\n",
        "      # user_query= extract_text_between_hashes(query)\n",
        "      results = self.service.cse().list(\n",
        "          q=query, cx=userdata.get('GOOGLE_CSE_ID'),  # Replace with your custom search engine ID\n",
        "          # searchType=\"image\",  # Specify image search\n",
        "          num=3\n",
        "      ).execute()\n",
        "\n",
        "      search_results = \" \"\n",
        "      for item in results.get(\"items\", []):\n",
        "          # for key, value in item.items():\n",
        "          #   print(\"\\033[32m\" + f\"{key}: {value}\" + \"\\033[0m\")\n",
        "          image_url = item[\"pagemap\"][\"cse_image\"][0][\"src\"]\n",
        "          # print(item[\"pagemap\"][\"metatags\"])\n",
        "          # search_results.append({\"link\":item[\"link\"] ,\n",
        "          #                       \"title\": item[\"title\"] ,\n",
        "          #                       \"snippets\":item[\"snippet\"],\n",
        "          #                       \"image\": image_url,\n",
        "          #                       \"meta\": extract_product_info(item[\"pagemap\"][\"metatags\"])})\n",
        "          if \"metatags\" in item[\"pagemap\"]:\n",
        "              search_results += self.extract_product_info(item[\"pagemap\"][\"metatags\"])\n",
        "\n",
        "\n",
        "          search_results += f\"image2: {image_url} \\n\"\n",
        "          search_results += f\"link: {item['link']}\"\n",
        "\n",
        "      # len(search_results)\n",
        "      return helper.clear_code(search_results)\n",
        "\n",
        "\n",
        "    def combined_scraped_api_search(self, query):\n",
        "      try:\n",
        "          # Attempt to perform scraping\n",
        "          scraped_results = self.google_scraper(query)\n",
        "      except Exception as e:\n",
        "          # Log the error\n",
        "          self.logger.error(\"Scraping failed with error: %s\", str(e))\n",
        "          scraped_results = \"Scraping failed\"\n",
        "\n",
        "      # Always perform search API even if scraper fails\n",
        "      search_api_results = self.search_google(query, 3)\n",
        "\n",
        "      # Combine results\n",
        "      combined_results = f\"{scraped_results}\\n{search_api_results}\"\n",
        "      # self.logger.info(\"Performing combined search for: %s\", query)\n",
        "      return combined_results\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "scraper = WebScraper()\n",
        "query = \"Apotheke 3 wick candles collection price images\"\n",
        "\n",
        "scraper.google_scraper(query)\n",
        "scraper.combined_scraped_api_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "qt2HTqzKykFj",
        "outputId": "c5b13db2-b5ef-47c9-b2ea-959e7aad6427"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GooglePlease clickhereif you are not redirected within a few seconds.AllImagesShoppingNewsMapsVideosBooksSearch toolsAny timeAny timePast hourPast 24 hoursPast weekPast monthPast yearAll resultsAll resultsVerbatim3-Wick Candles | APOTHEKEapothekeco.com  collections  3-wick-candlesMade with a premium soy wax blend and essential and perfume-grade fragrance oils, our luxury scented 3-wick candles are designed to provide a clean-burning...Charcoal 3-Wick Candle - Apothekeapothekeco.com  products  charcoal-3-wick-candleRating4.3(143)In stockThis 3-Wick Scented Candle is made with a premium soy wax blend and essential and perfume-grade fragrance oils in a chic matte-black glass vessel. The FragranceCanvas 3-Wick Candle - Apothekeapothekeco.com  products  canvas-3-wick-candleRating5.0(8)In stockThis 3-Wick Scented Candle is made with a premium soy wax blend and essential and perfume-grade fragrance oils in a luxe white-translucent glass vessel. The...APOTHEKE Market Collection Luxury Scented 3-Wick Jar Candle ...www.amazon.com  APOTHEKE-Market-Collection-Luxury-ScentedRating4.1(149)Buy APOTHEKE Market Collection Luxury Scented 3-Wick Jar Candle, Meyer Lemon & Mint, 32 oz - Lemon, Spearmint, Jasmine & Eucalyptus Scent, Strong Fragrance,...Saffron Vanilla 3-Wick Candle  APOTHEKEapothekeco.com  products  saffron-vanilla-3-wick-candleRating4.8(6)In stockCreate your paradise with the comforting and complex scent of Saffron Vanilla from the Eden Collection. This 3-Wick Scented Candle is made with a premium...Cedarwood Ginger 3-Wick Candle - Apothekeapothekeco.com  products  cedarwood-ginger-3-wick-candleRating5.0(1)In stockCreate your personal paradise with the enticing scent of Cedarwood Ginger from the Eden Collection. This 3-Wick Scented Candle is made with a premium soy...Amazon.com: Apotheke 3-Wick Candles Collectionwww.amazon.com  Scented-Candles-Home-Soy-Wax-Jar-CandleRating4.1(149)Our candles are hand poured and made with a proprietary blend of essential and perfume-grade oils for a long-lasting fragrance. Each 26 oz candle burns for...Shop All Candles | APOTHEKEapothekeco.com  collections  candles-votives-and-3-wicksCandles & Diffusers  Candles  Best Selling Fragrance  Classic Candles  2-Wick Ceramic Candles  3-Wick Candles  Fragrance Bundles  Discovery Sets  Mini...People also askAre 3 wick candles worth it?How long do Apotheke candles last?Are Apotheke candles natural?Do you light all 3 wicks on a 3 wick candle?APOTHEKE 3-Wick Candle - Goodywww.ongoody.com  apotheke  3-wick-candle-recipient-s-choice-1$78.00Hand-poured with perfume-grade fragrance oils and a high quality soy wax blend. This scent is formulated with a unique wick, wax, and fragrance combination...Apotheke - Tonka Oak 3 Wick Candlewww.candledelirium.com  apotheke-tonka-oak-3-wick-candle$78.00Apotheke Canvas Candle is where crisp linen, white musk, and sweet lily of the valley mingle with a dew drop accord for a clean, refreshing scent.&l.Related searchesApotheke 3 wick candles collection where to buyApotheke 3 wick candles collection wholesaleApotheke 3 wick candles collection saleApotheke 3 wick candles collection reviewapotheke charcoal 3-wick candlecheapest 3-wick candles bath and body works3 wick candles not in a Jar3-Wick Candle saleNext >United StatesFrom your IP address-Learn moreSign inSettingsPrivacyTermsDark theme: Off'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "scraper.google_scraper(\"Apotheke 3 wick candles collection\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "SypGSDOh78Q4",
        "outputId": "0705d1f2-0f60-46e1-bfdd-66442bc165f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\n ***Title: Apotheke 3-Wick Candles Collection\\nDescription: Captivating Fragrance: Transform any living space with the unforgettable scent of Charcoal 3-Wick Candle from APOTHEKE. Our candles are hand poured and made with a proprietary blend of essential and perfume-grade oils for a long-lasting fragrance. Each 26 oz candle burns for approximately 120 - 1...\\nURL: https://www.amazon.com/dp/B07PMY9PK6/ref=tsm_1_fb_lk \\nAvailability: in stock\\nASIN: B07PMY9PK6 \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/61yZbIMhvVL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/Scented-Candles-Home-Soy-Wax-Jar-Candle/dp/B07PMY9PK6\\n ***Title: MSRP/MAP Policy\\nDescription: In order to preserve its reputation for providing customers with high value products and strong after-sales support, and to further enhance the APOTHEKE brand image and its competitiveness in the marketplace, APOTHEKE is unilaterally instituting a policy of minimum advertised price standards for APOTHEKE products.\\nImage URL: http:files/Charcoal2.jpg \\nURL: https://apothekeco.com/pages/msrpmap-policy \\nAvailability: Unknown\\nSite Name: APOTHEKE \\ntype: website \\nimage2: https://hello.zonos.com/images/flags/US.png \\nlink: https://apothekeco.com/pages/msrpmap-policy\\n ***Title: APOTHEKE Market Collection Luxury Scented 3-Wick Jar Candle, Purple Basil, 32 oz - Basil, Ginger Lime & Lily of The Valley Scent, Strong Fragrance, Aromatherapy, Long Lasting, Hand Poured in USA, Soy\\nDescription: APOTHEKE Luxury Jar Candles Purple Basil - 32 Ounce 3-Wick Jar Candle SCENT PROFILE: Purple basil, spicy ginger and juicy lime zest mingle with hints of lily of the valley Our candles are hand-poured with perfume-grade fragrance oils and a high quality soy wax blend. Each scent is formulated with...\\nURL: https://www.amazon.com/dp/B09RTPD6ZN/ref=tsm_1_fb_lk \\nAvailability: Unknown\\nASIN: B09RTPD6ZN \\ntype: text \\nimage2: https://m.media-amazon.com/images/I/618bD-pCyRL._AC_UF894,1000_QL80_.jpg \\nlink: https://www.amazon.com/APOTHEKE-Market-Collection-Luxury-Scented/dp/B09RTPD6ZN'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "scraper.search_google(\"Apotheke 3 wick candles collection price images\",3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXzSpNTmbjyU"
      },
      "source": [
        "# Document Spliting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5NgTJ-F4f0U3"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "class DocumentSplitter:\n",
        "    def __init__(self, chunk_size=700, chunk_overlap=150):\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "        self.splits = []\n",
        "\n",
        "    def split_document(self, document):\n",
        "        self.splits = self.text_splitter.split_text(document)\n",
        "        return self.splits\n",
        "\n",
        "    def split_document_with_metadata(self, document, metadata):\n",
        "        splits_with_metadata = []\n",
        "        splits = self.split_document(document)\n",
        "        for split in splits:\n",
        "            split_with_metadata = Document(\n",
        "                                    page_content=split,\n",
        "                                    metadata=metadata,\n",
        "                                    )\n",
        "            splits_with_metadata.append(split_with_metadata)\n",
        "        return splits_with_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SyZlX2crbxzD"
      },
      "outputs": [],
      "source": [
        "splitter = DocumentSplitter()\n",
        "# Split the document\n",
        "splits = splitter.split_document_with_metadata(scraper.combined_scraped_api_search(query),{\"source\":query, \"row\": 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6KHv2Un_x-1"
      },
      "source": [
        "# Embedding Docs in Vector DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gUF_S7BV_vHQ"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import shutil\n",
        "\n",
        "import os\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "class EmbeddingProcessor:\n",
        "    _instance = None\n",
        "\n",
        "    def __new__(cls, *args, **kwargs):\n",
        "        if cls._instance is None:\n",
        "            cls._instance = super().__new__(cls)\n",
        "            cls._instance._initialized = False\n",
        "        return cls._instance\n",
        "\n",
        "    def __init__(self, persist_directory='docs/chroma/'):\n",
        "        if not self._initialized:\n",
        "            os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "            openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "            self.embedding = OpenAIEmbeddings()\n",
        "            self.persist_directory = persist_directory\n",
        "            self.vectordb = None\n",
        "            self._initialized = True\n",
        "\n",
        "    def setup_vector_store(self):\n",
        "        import sys\n",
        "        sys.path.append('../..')\n",
        "\n",
        "        # Remove old database files if any\n",
        "        self.clear_vector_store()\n",
        "\n",
        "        # Initialize Chroma vector store\n",
        "        if self.vectordb is None:\n",
        "            self.vectordb = Chroma(\n",
        "                persist_directory=self.persist_directory,\n",
        "                embedding_function=self.embedding\n",
        "            )\n",
        "\n",
        "    def clear_vector_store(self):\n",
        "        if os.path.exists(self.persist_directory):\n",
        "            shutil.rmtree(self.persist_directory)\n",
        "            self.vectordb = None\n",
        "        else:\n",
        "            print(\"No vector store directory found.\")\n",
        "\n",
        "    def delete_collection(self):\n",
        "        if self.vectordb:\n",
        "            self.vectordb.delete_collection()\n",
        "        else:\n",
        "            raise ValueError(\"Vector store not initialized. Please call setup_vector_store first.\")\n",
        "\n",
        "    def store_splits_text(self, splits):\n",
        "        if not self.embedding:\n",
        "            raise ValueError(\"Embedding function not initialized.\")\n",
        "        # self.setup_vector_store()  # Ensure vector store is initialized\n",
        "        self.vectordb = Chroma.from_texts(splits, embedding=OpenAIEmbeddings())\n",
        "        return self.vectordb\n",
        "\n",
        "    def store_splits_doc(self, splits):\n",
        "        if not self.embedding:\n",
        "            raise ValueError(\"Embedding function not initialized.\")\n",
        "        # self.setup_vector_store()  # Ensure vector store is initialized\n",
        "        self.vectordb = Chroma.from_documents(splits, embedding=OpenAIEmbeddings())\n",
        "        return self.vectordb\n",
        "\n",
        "    def count_documents(self):\n",
        "        if self.vectordb:\n",
        "            return self.vectordb._collection.count()\n",
        "        else:\n",
        "            raise ValueError(\"Vector store not initialized. Please call setup_vector_store first.\")\n",
        "\n",
        "    def similarity_search(self, query, k=5, filter={\"source\": \"text\"}):\n",
        "        if self.vectordb:\n",
        "            return self.vectordb.similarity_search(query, k=k, filter=filter)\n",
        "        else:\n",
        "            raise ValueError(\"Vector store not initialized. Please call setup_vector_store first.\")\n",
        "\n",
        "    def get_relevant_documents(self, query, search_type=\"mmr\", search_kwargs={\"k\": 3}, filter={\"source\": \"text\"}):\n",
        "        if self.vectordb:\n",
        "            retriever = self.vectordb.as_retriever(search_type=search_type, search_kwargs=search_kwargs, filter=filter)\n",
        "            return retriever.get_relevant_documents(query)\n",
        "        else:\n",
        "            raise ValueError(\"Vector store not initialized. Please call setup_vector_store first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5NvXr9MRAuqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f401aa-d52f-4343-be1a-e549e45584fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No vector store directory found.\n"
          ]
        }
      ],
      "source": [
        "# Initialize the embedding processor\n",
        "ebprocessor = EmbeddingProcessor()\n",
        "# Setup vector store\n",
        "ebprocessor.setup_vector_store()\n",
        "# Create vector store from splits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2C2JE0TAA2Go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05339862-9623-454d-ca02-3bc9d5046e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 0\n"
          ]
        }
      ],
      "source": [
        "# processor.store_splits(splits)\n",
        "    # Count documents\n",
        "print(\"Number of documents:\", ebprocessor.count_documents())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbKQrEh5CUGR"
      },
      "source": [
        "# **Execution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8om8zzbWCTEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "677bcc58-4844-41ef-e2ea-a5bc0db37e41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'brand': 'Michael Kors',\n",
              "  'image': 'N/A',\n",
              "  'Sold on amazon': 'N/A',\n",
              "  'color': 'N/A',\n",
              "  'Amazon price': 'N/A',\n",
              "  'ASIN': 'N/A',\n",
              "  'UPC': 'N/A'},\n",
              " {'brand': 'Michael Kors',\n",
              "  'image': 'N/A',\n",
              "  'Sold on amazon': 'N/A',\n",
              "  'color': 'N/A',\n",
              "  'Amazon price': 'N/A',\n",
              "  'ASIN': 'N/A',\n",
              "  'UPC': 'N/A'},\n",
              " {'brand': 'Michael Kors',\n",
              "  'image': 'N/A',\n",
              "  'Sold on amazon': 'N/A',\n",
              "  'color': 'N/A',\n",
              "  'Amazon price': 'N/A',\n",
              "  'ASIN': 'N/A',\n",
              "  'UPC': 'N/A'},\n",
              " {'brand': 'Michael Kors',\n",
              "  'image': 'N/A',\n",
              "  'Sold on amazon': 'N/A',\n",
              "  'color': 'N/A',\n",
              "  'Amazon price': 'N/A',\n",
              "  'ASIN': 'N/A',\n",
              "  'UPC': 'N/A'},\n",
              " {'brand': 'Michael Kors',\n",
              "  'image': 'N/A',\n",
              "  'Sold on amazon': 'N/A',\n",
              "  'color': 'N/A',\n",
              "  'Amazon price': 'N/A',\n",
              "  'ASIN': 'N/A',\n",
              "  'UPC': 'N/A'},\n",
              " {'brand': 'Michael Kors',\n",
              "  'image': 'N/A',\n",
              "  'Sold on amazon': 'N/A',\n",
              "  'color': 'N/A',\n",
              "  'Amazon price': 'N/A',\n",
              "  'ASIN': 'N/A',\n",
              "  'UPC': 'N/A'},\n",
              " {'brand': 'Michael Kors',\n",
              "  'image': 'N/A',\n",
              "  'Sold on amazon': 'N/A',\n",
              "  'color': 'N/A',\n",
              "  'Amazon price': 'N/A',\n",
              "  'ASIN': 'N/A',\n",
              "  'UPC': 'N/A'},\n",
              " {'brand': 'Michael Kors',\n",
              "  'image': 'N/A',\n",
              "  'Sold on amazon': 'N/A',\n",
              "  'color': 'N/A',\n",
              "  'Amazon price': 'N/A',\n",
              "  'ASIN': 'N/A',\n",
              "  'UPC': 'N/A'},\n",
              " {'brand': 'Michael Kors',\n",
              "  'image': 'N/A',\n",
              "  'Sold on amazon': 'N/A',\n",
              "  'color': 'N/A',\n",
              "  'Amazon price': 'N/A',\n",
              "  'ASIN': 'N/A',\n",
              "  'UPC': 'N/A'},\n",
              " {'brand': 'Michael Kors',\n",
              "  'image': 'N/A',\n",
              "  'Sold on amazon': 'N/A',\n",
              "  'color': 'N/A',\n",
              "  'Amazon price': 'N/A',\n",
              "  'ASIN': 'N/A',\n",
              "  'UPC': 'N/A'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Get all rows' column values\n",
        "all_rows_column_values = analysis.get_all_rows_column_values()\n",
        "\n",
        "all_rows_column_values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to process each row\n",
        "def process_row(row_index, row_values):\n",
        "    # Fetch search query at index 0 with row_index\n",
        "    search_query = analysis.get_search_query_at_index(row_index)\n",
        "    print(\"\\033[34m\" + f\"search query :: {search_query}\" + \"\\033[0m\")\n",
        "    # Call splitter and scraper\n",
        "    splits = splitter.split_document_with_metadata(scraper.combined_scraped_api_search(search_query), {\"source\": search_query, \"row\": row_index})\n",
        "    print(f\"Splits for query at row index {row_index}:\")\n",
        "    print(splits)\n",
        "\n",
        "    # Store splits\n",
        "    ebprocessor.store_splits_doc(splits)\n",
        "\n",
        "    # Process `splits` as needed\n",
        "    # For example:\n",
        "    return splits\n",
        "\n",
        "# Use map to apply the function to each row\n",
        "results = list(map(process_row, range(len(analysis.get_all_rows_column_values())), analysis.get_all_rows_column_values()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "SvZqHHuDCQkn",
        "outputId": "122e05b8-45c6-40cf-82b8-08676b895b05"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34msearch query :: Michael Kors 30F1GCDS2L 001\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HttpError",
          "evalue": "<HttpError 429 when requesting https://customsearch.googleapis.com/customsearch/v1?q=Michael+Kors+30F1GCDS2L+001&cx=d078efeff9454401e&num=3&key=AIzaSyBMBwN5EJvN0RKg3ajOzuxb_LppXCuhTg4&alt=json returned \"Quota exceeded for quota metric 'Queries' and limit 'Queries per day' of service 'customsearch.googleapis.com' for consumer 'project_number:99572213829'.\". Details: \"[{'message': \"Quota exceeded for quota metric 'Queries' and limit 'Queries per day' of service 'customsearch.googleapis.com' for consumer 'project_number:99572213829'.\", 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-18479c8ba952>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Use map to apply the function to each row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_rows_column_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_rows_column_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-18479c8ba952>\u001b[0m in \u001b[0;36mprocess_row\u001b[0;34m(row_index, row_values)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\033[34m\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"search query :: {search_query}\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\033[0m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Call splitter and scraper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_document_with_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined_scraped_api_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"source\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msearch_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"row\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow_index\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Splits for query at row index {row_index}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-31005615d256>\u001b[0m in \u001b[0;36mcombined_scraped_api_search\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0;31m# Always perform search API even if scraper fails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0msearch_api_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m       \u001b[0;31m# Combine results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-31005615d256>\u001b[0m in \u001b[0;36msearch_google\u001b[0;34m(self, query, num_results)\u001b[0m\n\u001b[1;32m    185\u001b[0m           \u001b[0;31m# searchType=\"image\",  # Specify image search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m           \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m       ).execute()\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0msearch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 429 when requesting https://customsearch.googleapis.com/customsearch/v1?q=Michael+Kors+30F1GCDS2L+001&cx=d078efeff9454401e&num=3&key=AIzaSyBMBwN5EJvN0RKg3ajOzuxb_LppXCuhTg4&alt=json returned \"Quota exceeded for quota metric 'Queries' and limit 'Queries per day' of service 'customsearch.googleapis.com' for consumer 'project_number:99572213829'.\". Details: \"[{'message': \"Quota exceeded for quota metric 'Queries' and limit 'Queries per day' of service 'customsearch.googleapis.com' for consumer 'project_number:99572213829'.\", 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Empty columns:\", analysis.get_empty_columns())"
      ],
      "metadata": {
        "id": "s0pAPGucLkD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results\n",
        "for idx, splits in enumerate(results):\n",
        "    query = \" \".join(all_rows_column_values[idx].values())\n",
        "    print(\"Splits for query:\", query)\n",
        "    print(splits)"
      ],
      "metadata": {
        "id": "hUZMdCsECVye"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRpO/X+gnO26qTbws1eFh8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}